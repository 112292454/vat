# VAT æç¤ºè¯ä¼˜åŒ–å®Œæ•´æŒ‡å—ï¼ˆé›¶ä»£ç æ”¹åŠ¨ï¼‰

æœ¬æ–‡æ¡£è¯¦ç»†åˆ—å‡º VAT é¡¹ç›®ä¸­æ‰€æœ‰å¯ä»¥é€šè¿‡ä¿®æ”¹æç¤ºè¯ï¼ˆpromptï¼‰æ¥ä¼˜åŒ– vtuber ç›´æ’­å­—å¹•è´¨é‡çš„ä½ç½®ï¼ŒåŒ…æ‹¬ï¼š
- æç¤ºè¯æ¨¡æ¿æ–‡ä»¶ï¼ˆ`.md`ï¼‰
- é…ç½®æ–‡ä»¶ä¸­çš„è‡ªå®šä¹‰æç¤ºè¯å­—æ®µ
- å„ç¯èŠ‚çš„ä¼˜åŒ–ç­–ç•¥å’Œç¤ºä¾‹

---

## ğŸ“‹ ç›®å½•

1. [æç¤ºè¯ä½ç½®æ€»è§ˆ](#æç¤ºè¯ä½ç½®æ€»è§ˆ)
2. [ç¯èŠ‚ 1ï¼šWhisper ASR é˜¶æ®µ](#ç¯èŠ‚-1whisper-asr-é˜¶æ®µ)
3. [ç¯èŠ‚ 2ï¼šæ™ºèƒ½æ–­å¥ï¼ˆSplitï¼‰é˜¶æ®µ](#ç¯èŠ‚-2æ™ºèƒ½æ–­å¥splité˜¶æ®µ)
4. [ç¯èŠ‚ 3ï¼šå­—å¹•ä¼˜åŒ–ï¼ˆOptimizeï¼‰é˜¶æ®µ](#ç¯èŠ‚-3å­—å¹•ä¼˜åŒ–optimizeé˜¶æ®µ)
5. [ç¯èŠ‚ 4ï¼šç¿»è¯‘ï¼ˆTranslateï¼‰é˜¶æ®µ](#ç¯èŠ‚-4ç¿»è¯‘translateé˜¶æ®µ)
6. [vtuber åœºæ™¯ä¼˜åŒ–ç¤ºä¾‹](#vtuber-åœºæ™¯ä¼˜åŒ–ç¤ºä¾‹)

---

## æç¤ºè¯ä½ç½®æ€»è§ˆ

VAT é¡¹ç›®ä¸­æ¶‰åŠ LLM æç¤ºè¯çš„ä½ç½®ï¼š

| ç¯èŠ‚ | æç¤ºè¯ä½ç½® | ç±»å‹ | å¯ä¿®æ”¹æ€§ |
|------|-----------|------|---------|
| **Whisper ASR** | `config/default.yaml` â†’ `asr.initial_prompt` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |
| **æ™ºèƒ½æ–­å¥** | `vat/llm/prompts/split/sentence.md` | æ¨¡æ¿æ–‡ä»¶ | âœ… é›¶ä»£ç  |
| **æ™ºèƒ½æ–­å¥** | `vat/llm/prompts/split/semantic.md` | æ¨¡æ¿æ–‡ä»¶ | âš ï¸ éœ€æ”¹ä»£ç æ¿€æ´» |
| **æ™ºèƒ½æ–­å¥ï¼ˆåœºæ™¯ï¼‰** | `vat/llm/scenes.yaml` â†’ `scenes[i].prompts.split` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |
| **å­—å¹•ä¼˜åŒ–** | `vat/llm/prompts/optimize/subtitle.md` | æ¨¡æ¿æ–‡ä»¶ | âœ… é›¶ä»£ç  |
| **å­—å¹•ä¼˜åŒ–** | `config/default.yaml` â†’ `translator.llm.optimize.custom_prompt` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |
| **å­—å¹•ä¼˜åŒ–ï¼ˆåœºæ™¯ï¼‰** | `vat/llm/scenes.yaml` â†’ `scenes[i].prompts.optimize` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |
| **ç¿»è¯‘ï¼ˆæ ‡å‡†ï¼‰** | `vat/llm/prompts/translate/standard.md` | æ¨¡æ¿æ–‡ä»¶ | âœ… é›¶ä»£ç  |
| **ç¿»è¯‘ï¼ˆåæ€ï¼‰** | `vat/llm/prompts/translate/reflect.md` | æ¨¡æ¿æ–‡ä»¶ | âœ… é›¶ä»£ç  |
| **ç¿»è¯‘ï¼ˆé™çº§ï¼‰** | `vat/llm/prompts/translate/single.md` | æ¨¡æ¿æ–‡ä»¶ | âœ… é›¶ä»£ç  |
| **ç¿»è¯‘è‡ªå®šä¹‰** | `config/default.yaml` â†’ `translator.llm.custom_prompt` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |
| **ç¿»è¯‘ï¼ˆåœºæ™¯ï¼‰** | `vat/llm/scenes.yaml` â†’ `scenes[i].prompts.translate` | é…ç½®å­—æ®µ | âœ… é›¶ä»£ç  |

---

æœ¬æ–‡æ¡£æ˜¯æ€»ç»“äº†è¯¥è§†é¢‘ç¿»è¯‘é¡¹ç›®ä¸­ï¼Œç”¨åˆ°LLMå„å¤„çš„æç¤ºè¯å†™æ³•

å¹¶ä¸”ç›®å‰å°šæœªå®æ–½é’ˆå¯¹åœºæ™¯ï¼ˆVtuberç›´æ’­ï¼‰çš„ä¼˜åŒ–

å› æ­¤ï¼Œä¸‹é¢çš„å„ä¸ªå°èŠ‚çš„æ ¼å¼ä¸ºï¼š

```
part1ï¼š æŸç¯èŠ‚å½“å‰çš„æç¤ºè¯æ˜¯æ€ä¹ˆå†™çš„ï¼ˆæ¥è‡ªæŸä¸ªç»å…¸é¡¹ç›®ï¼‰

part2ï¼šä¼˜åŒ–å»ºè®®â€”â€”æˆ‘ä»¬è¦å¯¹äºè¿™éƒ¨åˆ†åšæ€æ ·çš„ä¿®æ”¹ï¼Œä¼˜åŒ–ï¼Œéœ€è¦ä½ å»å®Œæˆå¯¹ä¸Šè¿°ç¯èŠ‚å½“å‰æç¤ºè¯çš„ä¿®æ”¹ã€‚æˆ–ï¼šå¤§è‡´çš„ä¸€ä¸ªä¼˜åŒ–æ–¹å‘â€”â€”åªæ˜¯è¯´æ˜äº†ä¸€ä¸ªå¤§æ¦‚çš„æƒ³æ³•ï¼Œä½†æ˜¯å…·ä½“çš„ä¼˜åŒ–å†™æ³•å°šæœªè§„åˆ’ï¼Œéœ€è¦ä½ é¦–å…ˆè§„åˆ’ä¸Šè¿°æç¤ºè¯æ€ä¹ˆæ”¹ï¼Œæˆ–é¢å¤–æ·»åŠ çš„customæç¤ºè¯åº”è¯¥æ€ä¹ˆè®¾è®¡ã€‚ç„¶åä¸ç”¨æˆ·å•†è®¨è¿™ä¸ªæ€è·¯æ˜¯å¦å¯è¡Œï¼Œæœ€ååœ¨å®Œæˆå…·ä½“çš„æç¤ºè¯å†…å®¹
```

è¯·ä½ åœ¨åç»­å®Œå–„æ—¶ï¼Œæ ¹æ®ä¸Šè¿°è¯´æ˜ç†è§£ï¼Œå¹¶ååŠ©å®Œæˆå·¥ä½œã€‚


## ç¯èŠ‚ 1ï¼šæ™ºèƒ½æ–­å¥ï¼ˆSplitï¼‰é˜¶æ®µ

### ä½ç½® 1ï¼šæ–­å¥é•¿åº¦é…ç½®
**é…ç½®å­—æ®µ**ï¼š`config/default.yaml` â†’ `asr.split.*`

```yaml
asr:
  split:
    enable: true
    mode: "sentence"  # å½“å‰ä»£ç å›ºå®šä½¿ç”¨ sentenceï¼Œsemantic æ¨¡å¼éœ€æ”¹ä»£ç æ¿€æ´»
    max_words_cjk: 24      # ä¸­æ–‡/æ—¥æ–‡æ¯å¥æœ€å¤§å­—ç¬¦æ•°
    max_words_english: 18  # è‹±æ–‡æ¯å¥æœ€å¤§å•è¯æ•°
    model: "gpt-4o-mini"   # æ–­å¥ä½¿ç”¨çš„ LLM æ¨¡å‹
    
    # åˆ†å—é…ç½®ï¼ˆæ–°å¢ï¼‰- ç”¨äºå¤„ç†é•¿è§†é¢‘
    enable_chunking: true          # æ˜¯å¦å¯ç”¨åˆ†å—å¤„ç†
    chunk_size_sentences: 50       # æ¯å—çš„å¥å­æ•°
    chunk_overlap_sentences: 5     # å—é—´é‡å çš„å¥å­æ•°
    chunk_min_threshold: 30        # å°äºæ­¤å€¼ä¸åˆ†å—ï¼Œç›´æ¥å…¨æ–‡å¤„ç†
```

#### vtuber åœºæ™¯ä¼˜åŒ–å»ºè®®

| åœºæ™¯ | max_words_cjk | max_words_english | åŸå›  |
|------|--------------|------------------|------|
| **æ¸¸æˆç›´æ’­** | 16-20 | 12-15 | å¿«èŠ‚å¥ï¼Œéœ€è¦çŸ­å¥å¿«é€Ÿæ˜¾ç¤º |
| **é—²èŠç›´æ’­** | 24-28 | 18-22 | æ­£å¸¸è¯­é€Ÿï¼Œå¯ä»¥ç¨é•¿ä¿æŒè¯­ä¹‰å®Œæ•´ |
| **ASMR** | 12-18 | 10-14 | è½»å£°ç»†è¯­ï¼ŒçŸ­å¥è¥é€ æ°›å›´ |
| **æ•™å­¦/è§£è¯´** | 28-32 | 20-25 | ä¿¡æ¯å¯†åº¦é«˜ï¼Œé•¿å¥ä¿æŒå®Œæ•´æ€§ |

### ä½ç½® 1ï¼šæ–­å¥æç¤ºè¯æ¨¡æ¿
**æ¨¡æ¿æ–‡ä»¶**ï¼š`vat/llm/prompts/split/sentence.md`ï¼ˆå½“å‰ä½¿ç”¨ï¼‰

#### å½“å‰æ¨¡æ¿ç»“æ„
```markdown
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­—å¹•åˆ†æ®µä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æœªåˆ†æ®µçš„è¿ç»­æ–‡æœ¬æŒ‰è¯­ä¹‰æ–­ç‚¹æ‹†åˆ†,ä½¿å­—å¹•ä¾¿äºé˜…è¯»å’Œç†è§£ã€‚

<instructions>
1. åœ¨è¯­ä¹‰è‡ªç„¶æ–­ç‚¹å¤„æ’å…¥ <br>(å¯åœ¨å¥å†…ã€å¥é—´çµæ´»åˆ†æ®µ)
2. å­—æ•°é™åˆ¶:
   - CJKè¯­è¨€(ä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ç­‰):æ¯æ®µâ‰¤ $max_word_count_cjk å­—
   - æ‹‰ä¸è¯­è¨€(è‹±è¯­ã€æ³•è¯­ç­‰):æ¯æ®µâ‰¤ $max_word_count_english è¯
3. æ¯æ®µéœ€åŒ…å«å®Œæ•´è¯­ä¹‰,é¿å…è¿‡çŸ­ç¢ç‰‡
4. åŸæ–‡ä¿æŒä¸å˜:ä¸å¢åˆ æ”¹,ä»…æ’å…¥ <br>
5. ç›´æ¥è¾“å‡ºåˆ†æ®µæ–‡æœ¬,æ— éœ€è§£é‡Š
</instructions>

<output_format>
ç›´æ¥è¾“å‡ºåˆ†æ®µåçš„æ–‡æœ¬,æ®µä¸æ®µä¹‹é—´ç”¨ <br> åˆ†éš”,ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹æˆ–è§£é‡Šã€‚
</output_format>

<examples>
<example>
<input>
å¤§å®¶å¥½ä»Šå¤©æˆ‘ä»¬å¸¦æ¥çš„3dåˆ›æ„è®¾è®¡ä½œå“æ˜¯è¿›åˆ¶æ¼”ç¤ºå™¨æˆ‘æ˜¯æ¥è‡ªä¸­å±±å¤§å­¦é™„å±ä¸­å­¦çš„æ–¹è‹¥æ¶µæˆ‘æ˜¯é™ˆæ¬£ç„¶æˆ‘ä»¬è¿™ä¸€æ¬¡ä½œå“ä»‹ç»åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ç¬¬ä¸€ä¸ªéƒ¨åˆ†æå‡ºé—®é¢˜ç¬¬äºŒä¸ªéƒ¨åˆ†è§£å†³æ–¹æ¡ˆç¬¬ä¸‰ä¸ªéƒ¨åˆ†ä½œå“ä»‹ç»å½“æˆ‘ä»¬å­¦ä¹ è¿›åˆ¶çš„æ—¶å€™éš¾ä»¥æŒæ¡è€å¸ˆæ•™å­¦ ä¹Ÿæ¯”è¾ƒæŠ½è±¡é‚£æœ‰æ²¡æœ‰ä¸€ç§æ•™å…·æˆ–æ¼”ç¤ºå™¨å¯ä»¥å°†è¿›åˆ¶çš„åŸç†å½¢è±¡ç”ŸåŠ¨åœ°å±•ç°å‡ºæ¥
</input>
<output>
å¤§å®¶å¥½<br>ä»Šå¤©æˆ‘ä»¬å¸¦æ¥çš„3dåˆ›æ„è®¾è®¡ä½œå“æ˜¯<br>è¿›åˆ¶æ¼”ç¤ºå™¨<br>æˆ‘æ˜¯æ¥è‡ªä¸­å±±å¤§å­¦é™„å±ä¸­å­¦çš„æ–¹è‹¥æ¶µ<br>æˆ‘æ˜¯é™ˆæ¬£ç„¶<br>æˆ‘ä»¬è¿™ä¸€æ¬¡ä½œå“ä»‹ç»åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†<br>ç¬¬ä¸€ä¸ªéƒ¨åˆ†æå‡ºé—®é¢˜<br>ç¬¬äºŒä¸ªéƒ¨åˆ†è§£å†³æ–¹æ¡ˆ<br>ç¬¬ä¸‰ä¸ªéƒ¨åˆ†ä½œå“ä»‹ç»<br>å½“æˆ‘ä»¬å­¦ä¹ è¿›åˆ¶çš„æ—¶å€™éš¾ä»¥æŒæ¡<br>è€å¸ˆæ•™å­¦ä¹Ÿæ¯”è¾ƒæŠ½è±¡<br>é‚£æœ‰æ²¡æœ‰ä¸€ç§æ•™å…·æˆ–æ¼”ç¤ºå™¨<br>å¯ä»¥å°†è¿›åˆ¶çš„åŸç†å½¢è±¡ç”ŸåŠ¨åœ°å±•ç°å‡ºæ¥
</output>
</example>

<example>
<input>
the upgraded claude sonnet is now available for all users developers can build with the computer use beta on the anthropic api amazon bedrock and google cloud's vertex ai the new claude haiku will be released later this month
</input>
<output>
the upgraded claude sonnet is now available for all users<br>developers can build with the computer use beta<br>on the anthropic api amazon bedrock and google cloud's vertex ai<br>the new claude haiku will be released later this month
</output>
</example>
</examples>

```

ä»£ç å®ç°ï¼š
```python
# åˆ†å—
def _create_chunks(
    self, segments: List[ASRDataSeg]
) -> List[Tuple[List[ASRDataSeg], int, int]]:
    """
    åˆ›å»ºå¸¦ overlap çš„åˆ†å—
    
    Returns:
        List[(chunk_segments, start_idx, end_idx)]
    """
    chunks = []
    total = len(segments)
    i = 0
    
    while i < total:
        end = min(i + self.chunk_size, total)
        chunk_segs = segments[i:end]
        chunks.append((chunk_segs, i, end - 1))
        
        # ä¸‹ä¸€å—çš„èµ·ç‚¹ï¼šå½“å‰å—æœ«å°¾ - overlap
        i = end - self.overlap
        
        # å¦‚æœå‰©ä½™ç‰‡æ®µå¤ªå°‘ï¼ˆä¸è¶³ overlap çš„ä¸€åŠï¼‰ï¼Œåˆå¹¶åˆ°å½“å‰å—
        if i > 0 and total - i < self.overlap // 2:
            break
    
    return chunks

â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦

chunks = self._create_chunks(segments)
logger.info(f"å°† {total} ä¸ªç‰‡æ®µåˆ†ä¸º {len(chunks)} å—å¤„ç†")

# é€å—æ–­å¥ï¼ˆä¸²è¡Œï¼Œå› ä¸ºéœ€è¦å‰å—ç»“æœï¼‰
all_split_segments = []

for i, (chunk_segs, start_idx, end_idx) in enumerate(chunks, 1):
    if progress_callback:
        progress_callback(f"æ–­å¥è¿›åº¦: {i}/{len(chunks)} å—")
    
    logger.info(f"å¤„ç†ç¬¬ {i}/{len(chunks)} å— (ç‰‡æ®µ {start_idx}-{end_idx})")
    
    # åˆå¹¶è¯¥å—çš„æ–‡æœ¬
    chunk_text = "".join(seg.text for seg in chunk_segs)
    
    # è°ƒç”¨ LLM æ–­å¥
    split_texts = split_by_llm(
        chunk_text,
        model=self.model,
        max_word_count_cjk=self.max_word_count_cjk,
        max_word_count_english=self.max_word_count_english,
        scene_prompt=self.scene_prompt,
    )
    
    # é‡æ–°åˆ†é…æ—¶é—´æˆ³
    chunk_asr = ASRData(chunk_segs)
    split_asr = self._realign_timestamps(chunk_asr, split_texts)
    
    # åˆå¹¶ç»“æœï¼ˆå¤„ç† overlapï¼‰
    if i == 1:
        # ç¬¬ä¸€å—ï¼Œå…¨éƒ¨ä¿ç•™
        all_split_segments.extend(split_asr.segments)
    else:
        # åç»­å—ï¼šè·³è¿‡ overlap éƒ¨åˆ†ï¼Œä½†ä¿ç•™æœ€åä¸€å¥çš„ä¼˜åŒ–ç‰ˆæœ¬
        # ç­–ç•¥ï¼šAçš„æœ€åä¸€å¥ä¸¢å¼ƒï¼ˆæ— ä¸‹æ–‡ï¼‰ï¼Œç”¨Bçš„ç¬¬ä¸€å¥ï¼ˆæœ‰ä¸Šä¸‹æ–‡ï¼‰
        # ä½†å¦‚æœ overlap=1ï¼Œå°±è¿˜æ˜¯ç”¨ A çš„
        if self.overlap == 1:
            # overlap=1 æ—¶ç”¨å‰å—çš„ç»“æœ
            all_split_segments.extend(split_asr.segments[self.overlap:])
        else:
            # overlap>1 æ—¶ï¼Œä¸¢å¼ƒå‰å—æœ€åä¸€å¥ï¼Œç”¨å½“å‰å—çš„ç¬¬ä¸€å¥
            # å…ˆç§»é™¤å‰å—çš„æœ€åä¸€å¥
            all_split_segments = all_split_segments[:-1]
            # å½“å‰å—è·³è¿‡å‰ overlap-1 å¥ï¼Œä»ç¬¬ overlap å¥å¼€å§‹ï¼ˆå³ä¿ç•™å½“å‰å—çš„ç¬¬ä¸€å¥ï¼‰
            all_split_segments.extend(split_asr.segments[self.overlap - 1:])
```


#### ä¼˜åŒ–å»ºè®®ï¼šé’ˆå¯¹ vtuber ç›´æ’­ç‰¹ç‚¹

**ä¿®æ”¹ç‚¹ 1**ï¼šåœ¨ `<instructions>` éƒ¨åˆ†å¢åŠ ç›´æ’­ç‰¹æœ‰è§„åˆ™

```markdown
<instructions>
1. åœ¨å¥å­è¾¹ç•Œå¤„æ’å…¥ <br> (å¥å·ã€é€—å·ã€åˆ†å·ç­‰æ ‡ç‚¹ç¬¦å·åº”å‡ºç°çš„ä½ç½®)
2. åˆ†å‰²æ®µçš„å­—æ•°é™åˆ¶:
   - CJKè¯­è¨€(ä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ç­‰):æ¯æ®µâ‰¤ ${max_word_count_cjk} å­—
   - æ‹‰ä¸è¯­è¨€(è‹±è¯­ã€æ³•è¯­ç­‰):æ¯æ®µâ‰¤ ${max_word_count_english} è¯
3. åœ¨éµå¾ªå­—æ•°é™åˆ¶çš„åŒæ—¶ï¼Œä¿æŒæ¯ä¸ªåˆ†å¥çš„æ„æ€å®Œæ•´
4. åŸæ–‡ä¿æŒä¸å˜:ä¸å¢åˆ æ”¹,ä¸è¦ç¿»è¯‘ï¼Œä»…æ’å…¥ <br>
5. å€’è®¡æ—¶ï¼ˆæ¯ä¸ªæ•°å­—è¿›è¡Œåˆ†å‰²ï¼‰ã€å…³é”®ä¿¡æ¯æ­ç¤ºå‰åŠéœ€è¦å¼ºè°ƒçš„ä½ç½®éœ€è¦è¿›è¡Œé€‚å½“åˆ†å‰²

<!-- æ–°å¢ï¼švtuber ç›´æ’­ä¸“ç”¨è§„åˆ™ -->
6. å£ç™–å’Œè¯­æ°”è¯ï¼ˆå¦‚"å•Š"ã€"å—¯"ã€"å“ˆ"ã€"ww"ï¼‰é€šå¸¸ä¸å‰å¥åˆå¹¶ï¼Œé™¤éå•ç‹¬æˆå¥ä½œä¸ºå¼ºè°ƒ
7. æ¸¸æˆæœ¯è¯­ã€æŠ€èƒ½åç§°ä¿æŒå®Œæ•´ï¼Œä¸åœ¨ä¸­é—´æ–­å¥
8. é‡å¤æ„Ÿå¹ï¼ˆå¦‚"å•Šå•Šå•Š"ã€"è‰è‰è‰"ï¼‰å¯ç‹¬ç«‹æˆæ®µä»¥ä½“ç°æƒ…ç»ªå¼ºåº¦
9. ä¸»æ’­ä¸è§‚ä¼—äº’åŠ¨ï¼ˆå¦‚"è°¢è°¢xxçš„SC"ï¼‰ä¼˜å…ˆç‹¬ç«‹æˆå¥
</instructions>
```

æ³¨æ„ ä¸Šè¿°æ–°å¢å†…å®¹ä¸æ˜¯æœ€ç»ˆçš„ä¿®æ”¹ç‰ˆï¼Œä½†æ˜¯å¯ä»¥å‚è€ƒé‡‡çº³ã€‚è¯·ä½ æ ¹æ®vtuberç›´æ’­æƒ…æ™¯ï¼Œå®Œæˆå…·ä½“çš„ä¿®æ”¹å†…å®¹

éœ€è¦å‚è€ƒçš„ä¿¡æ¯å¦‚ä¸‹ï¼š

é»˜è®¤å¯ä»¥å¤„ç†ä¸åŒçš„ä»»åŠ¡ï¼ˆåŒ…æ‹¬å„ç§è¯­è¨€çš„å„ä¸ªvtuberã€æ²¹ç®¡åšä¸»ç­‰ï¼‰ï¼Œä½†æ˜¯æ›´å€¾å‘äºæ—¥æœ¬äººvtuberï¼ˆä¸è¦æ˜¾å¼å†™å‡ºæ¥ï¼‰
é»˜è®¤çš„
åˆ†è¯åº”è¯¥çµæ´»å‚è€ƒè¯­ä¹‰ï¼Œç»“åˆä¸Šä¸‹æ–‡ä¸ä¸Šè¿°èƒŒæ™¯ï¼Œä½†ä¸å¾—ä¿®æ”¹å†…å®¹ï¼ˆå³ä¾¿å¯èƒ½åŸæ–‡çœ‹èµ·æ¥æœ‰è¯¯â€”â€”ä¾‹å¦‚å§äººåè¯†åˆ«æˆæŸä¸ªåè¯å¯¼è‡´ä¸è¿è´¯ï¼‰ã€‚å› ä¸ºåç»­è¿˜æœ‰å­—å¹•å†…å®¹ä¼˜åŒ–ç¯èŠ‚

### ä½ç½® 2ï¼šåœºæ™¯ç‰¹å®šçš„æ–­å¥æç¤ºè¯ï¼ˆæ–°å¢ï¼‰
**é…ç½®æ–‡ä»¶**ï¼š`vat/llm/scenes.yaml` â†’ `scenes[i].prompts.split`

æ¯ä¸ªåœºæ™¯å¯é…ç½®ç‹¬ç«‹çš„æ–­å¥æç¤ºè¯ï¼Œè¡¥å……å…¨å±€çš„ sentence.md æ¨¡æ¿ã€‚æ‰§è¡Œæµç¨‹ï¼š
1. å…ˆåŠ è½½å…¨å±€æ¨¡æ¿ `split/sentence.md`
2. åœ¨ä¸‹è½½æ—¶è¯†åˆ«è§†é¢‘åœºæ™¯ï¼ˆç”± LLM æ ¹æ®æ ‡é¢˜å’Œç®€ä»‹åˆ¤æ–­ï¼‰
3. ç¿»è¯‘å‰ä» `scenes.yaml` åŠ è½½å¯¹åº”åœºæ™¯çš„ `split` æç¤ºè¯
4. åœºæ™¯æç¤ºè¯å°†ä¸å…¨å±€æ¨¡æ¿åˆå¹¶åå‘é€ç»™ LLM

#### ç¤ºä¾‹ï¼šæ¸¸æˆç›´æ’­çš„æ–­å¥è§„åˆ™

ï¼ˆæ­¤å¤„ç¬¬ä¸€æ¬¡å‡ºç°åœºæ™¯ç‰¹å®šçš„æç¤ºè¯ï¼Œé¡¾å±•ç¤ºä¸€ä¸ªå®Œæ•´çš„ymlç»“æ„ã€‚åç»­å°†åªå±•ç¤ºç›¸å…³ä½ç½®ï¼‰

```yaml

scenes:
  - id: "gaming"
    name: "æ¸¸æˆç›´æ’­"
    description: "Playing video games with commentary and reactions. Includes competitive gaming, casual gaming, game tutorials."
    keywords:
      - "game"
      - "gameplay"
      - "boss"
      - "level"
      - "play"
      - "ã‚²ãƒ¼ãƒ "
      - "ãƒ—ãƒ¬ã‚¤"
    
    prompts:
      # æ–­å¥é˜¶æ®µçš„åœºæ™¯ç‰¹å®šæç¤ºè¯
      split: |
        ## æ¸¸æˆç›´æ’­æ–­å¥è§„åˆ™
        - æˆ˜æ–—/ç´§å¼ æ—¶åˆ»ä½¿ç”¨æ›´çŸ­çš„åˆ†å¥ï¼Œçªå‡ºèŠ‚å¥æ„Ÿ
        - æ„Ÿå¹è¯å’Œæƒ…ç»ªçˆ†å‘ï¼ˆ"å•Šå•Šå•Š"ã€"è‰"ï¼‰å•ç‹¬æˆå¥æˆ–ç´§è·Ÿå‰å¥
        - æ¸¸æˆæœ¯è¯­ä¸è¦ä»ä¸­é—´æ–­å¼€ï¼ˆå¦‚"Bossæˆ˜"ã€"æŠ€èƒ½CD"ä¿æŒå®Œæ•´ï¼‰
        - è¿ç»­å¿«é€Ÿååº”å¯ä»¥ç¨å¾®è¶…å‡ºå­—æ•°é™åˆ¶ï¼Œä¿æŒç´§å‡‘æ„Ÿ
      
      # ç¿»è¯‘é˜¶æ®µçš„åœºæ™¯ç‰¹å®šæç¤ºè¯ï¼ˆè¡¥å……å…¨å±€ custom_promptï¼‰
      translate: |
        ## æ¸¸æˆç›´æ’­åœºæ™¯ç‰¹ç‚¹
        - å¿«èŠ‚å¥å¯¹è¯ï¼Œæœ¯è¯­å‡†ç¡®æ€§ä¼˜å…ˆäºæ–‡å­¦æ€§
        - æˆ˜æ–—/ç´§å¼ æ—¶åˆ»ï¼šçŸ­å¥ã€æœ‰åŠ›ã€æ„Ÿå¹è¯ä¿ç•™æƒ…ç»ªå¼ºåº¦
        - æ¸¸æˆæœ¯è¯­ç»Ÿä¸€ï¼šBoss/HP/MP/Skill ç­‰ä¿æŒç¤¾åŒºä¹ æƒ¯
        - å¤±è´¥/æˆåŠŸçš„æƒ…ç»ªè¡¨è¾¾è¦å¼ºçƒˆï¼ˆ"å¯„äº†"ã€"è‰"ã€"ç‰›"ã€"ç»æ€"ï¼‰
        - æ•°å€¼ç›´æ¥ä¿ç•™ï¼ˆ"10% HP" â†’ "10%è¡€" æˆ– "æ²¡è¡€äº†"ï¼‰
      
      # ä¼˜åŒ–é˜¶æ®µçš„åœºæ™¯ç‰¹å®šæç¤ºè¯
      optimize: |
        ## æ¸¸æˆç›´æ’­ä¼˜åŒ–è§„åˆ™
        - ä¿ç•™æ¸¸æˆæœ¯è¯­çš„åŸæ–‡æˆ–ç¤¾åŒºé€šç”¨è¯‘å
        - ä¿ç•™æƒ…ç»ªåŒ–é‡å¤ï¼ˆ"å•Šå•Šå•Š"ã€"è‰è‰è‰"ï¼‰
        - ç§»é™¤çŠ¹è±«è¯ï¼ˆ"ã‚ã®"ã€"ãˆãˆã¨"ï¼‰ï¼Œä½†ä¿ç•™æˆ˜æ–—æ—¶çš„è¯­æ°”è¯

```

é‚£ä¹ˆæ­¤å¤„ï¼Œæˆ‘ä»¬ä¸»è¦æ˜¯å®Œæˆä¸Šè¿°çš„splitéƒ¨åˆ†



#### åº”ç”¨åœºæ™¯ï¼š

system promptå³ä¸Šä¸€èŠ‚çš„ç¤ºä¾‹å†…å®¹

æ­¤èŠ‚å†…å®¹å°†è¿™æ ·è¢«åº”ç”¨ï¼š

```python
system_prompt = get_prompt(
    prompt_path,
    max_word_count_cjk=max_word_count_cjk,
    max_word_count_english=max_word_count_english,
)

# æ’å…¥åœºæ™¯ç‰¹å®šæç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
if scene_prompt:
    # åœ¨ </instructions> ä¹‹åæ’å…¥åœºæ™¯æç¤ºè¯
    insert_marker = "</instructions>"
    if insert_marker in system_prompt:
        scene_block = f"\n\n<scene_specific>\n{scene_prompt.strip()}\n</scene_specific>"
        system_prompt = system_prompt.replace(
            insert_marker, 
            insert_marker + scene_block
        )
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°ï¼Œè¿½åŠ åˆ°æœ«å°¾
        system_prompt = f"{system_prompt}\n\n<scene_specific>\n{scene_prompt.strip()}\n</scene_specific>"

user_prompt = (
    f"Please use multiple <br> tags to separate the following sentence:\n{text}"
)
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_prompt},
]

```
ï¼ˆæ³¨æ„ï¼Œæ­¤å¤„å³åç»­æ‰€æœ‰ä½ç½®çš„scene_promptå‡ä¸åŒ…å«ä¸‹é¢ymlä¸­çš„idã€å…³é”®è¯ç­‰ã€‚ä»…åŒ…å«prompts.splitæˆ–è€…å…¶ä»–é˜¶æ®µç¼©å†™çš„å†…å®¹ï¼‰

é‚£ä¹ˆï¼Œè¯·ä½ é’ˆå¯¹æ­¤ç¯èŠ‚ï¼Œå®Œæˆä¸‹é¢å¤šä¸ªåœºæ™¯çš„split customæç¤ºè¯ä¼˜åŒ–ï¼š

```yaml
# vtuber ç›´æ’­åœºæ™¯é…ç½®
# æ¯ä¸ªåœºæ™¯åŒ…å«ï¼šIDã€åç§°ã€æè¿°ã€å…³é”®è¯ã€å„é˜¶æ®µçš„é¢å¤–æç¤ºè¯

scenes:
  - id: "gaming"
    name: "æ¸¸æˆç›´æ’­"
    description: "Playing video games with commentary and reactions. Includes competitive gaming, casual gaming, game tutorials."
    keywords:
      - "game"
      - "gameplay"
      - "boss"
      - "level"
      - "play"
      - "ã‚²ãƒ¼ãƒ "
      - "ãƒ—ãƒ¬ã‚¤"
    ï¼ˆä¸Šè¿°å†…å®¹å†åˆ†è¯é˜¶æ®µä¸ä¼šï¼‰
    prompts:
      # æ–­å¥é˜¶æ®µçš„åœºæ™¯ç‰¹å®šæç¤ºè¯
      split: |
        ## æ¸¸æˆç›´æ’­æ–­å¥è§„åˆ™
        - æˆ˜æ–—/ç´§å¼ æ—¶åˆ»ä½¿ç”¨æ›´çŸ­çš„åˆ†å¥ï¼Œçªå‡ºèŠ‚å¥æ„Ÿ
        - æ„Ÿå¹è¯å’Œæƒ…ç»ªçˆ†å‘ï¼ˆ"å•Šå•Šå•Š"ã€"è‰"ï¼‰å•ç‹¬æˆå¥æˆ–ç´§è·Ÿå‰å¥
        - æ¸¸æˆæœ¯è¯­ä¸è¦ä»ä¸­é—´æ–­å¼€ï¼ˆå¦‚"Bossæˆ˜"ã€"æŠ€èƒ½CD"ä¿æŒå®Œæ•´ï¼‰
        - è¿ç»­å¿«é€Ÿååº”å¯ä»¥ç¨å¾®è¶…å‡ºå­—æ•°é™åˆ¶ï¼Œä¿æŒç´§å‡‘æ„Ÿ

(å…¶ä»–é˜¶æ®µç•¥ï¼Œåé¢å†å¤„ç†ï¼Œä¸‹åŒ)

  - id: "chatting"
    name: "é—²èŠç›´æ’­"
    description: "Casual conversation, Q&A session, daily life sharing, viewer interaction."
    keywords:
      - "chat"
      - "talk"
      - "é›‘è«‡"
      - "freetalk"
      - "zatsudan"
    
    prompts:
      split: |
        ## é—²èŠç›´æ’­æ–­å¥è§„åˆ™
        - ä¿æŒè‡ªç„¶çš„å£è¯­èŠ‚å¥ï¼Œä¸è¦è¿‡åº¦åˆ‡åˆ†
        - è¯­æ°”è¯ï¼ˆ"å—¯"ã€"å•Š"ã€"å‘¢"ï¼‰å¯ä»¥è·Ÿéšå‰å¥ï¼Œä¸å¿…å•ç‹¬æˆå¥
        - å¯¹è§‚ä¼—çš„äº’åŠ¨å¥ä¿æŒå®Œæ•´ï¼ˆå¦‚"å¤§å®¶å¥½"ã€"è°¢è°¢xxx"ï¼‰
        - è¯é¢˜è½¬æ¢å¤„æ˜¯è‡ªç„¶æ–­ç‚¹

  - id: "asmr"
    name: "ASMRæ”¾æ¾"
    description: "ASMR content with soft speaking, whispering, relaxation, sleep aid, trigger sounds."
    keywords:
      - "asmr"
      - "relax"
      - "sleep"
      - "whisper"
      - "è€³ã‹ã"
      - "ç™’ã—"
    
    prompts:
      split: |
        ## ASMR æ–­å¥è§„åˆ™
        - çŸ­å¥ä¸ºä¸»ï¼Œè¥é€ è½»æŸ”èŠ‚å¥
        - æ‹Ÿå£°è¯ï¼ˆã•ã•ã€ãµã‚ãµã‚ï¼‰å¯å•ç‹¬æˆå¥æˆ–ç´§è·ŸåŠ¨ä½œæè¿°
        - åœé¡¿å’Œå‘¼å¸éŸ³æ ‡è®°æ˜¯è‡ªç„¶æ–­ç‚¹
        - ä¸è¦æŠŠèˆ’ç¼“çš„é•¿å¥å¼ºè¡Œæ‹†æ•£ï¼Œä¿æŒæ„å¢ƒå®Œæ•´


  - id: "singing"
    name: "æ­Œå›ç›´æ’­"
    description: "Singing stream, karaoke, music performance, song covers."
    keywords:
      - "sing"
      - "song"
      - "karaoke"
      - "æ­Œ"
      - "ã‚«ãƒ©ã‚ªã‚±"
      - "utawaku"
    
    prompts:
      split: |
        ## æ­Œå›æ–­å¥è§„åˆ™
        - æ­Œè¯éƒ¨åˆ†æŒ‰æ­Œæ›²åŸæœ‰èŠ‚å¥æ–­å¥ï¼ˆå‚è€ƒåŸæ›²åˆ†å¥ï¼‰
        - è¯´è¯éƒ¨åˆ†æŒ‰æ­£å¸¸å£è¯­æ–­å¥
        - æ­Œæ›²åã€æ­Œæ‰‹åä¿æŒå®Œæ•´ä¸è¦æ‹†å¼€
        - å”±å®Œåçš„æ„Ÿå¹/è¯„è®ºå¯ä»¥ç¨é•¿ï¼Œä¿æŒæƒ…ç»ªå®Œæ•´


  - id: "teaching"
    name: "æ•™å­¦è§£è¯´"
    description: "Tutorial, educational content, knowledge sharing, explanation streams."
    keywords:
      - "tutorial"
      - "how to"
      - "guide"
      - "explain"
      - "æ•™å­¦"
      - "è¬›åº§"
    
    prompts:
      split: |
        ## æ•™å­¦æ–­å¥è§„åˆ™
        - æŒ‰é€»è¾‘æ­¥éª¤æ–­å¥ï¼ˆ"é¦–å…ˆ"ã€"ç„¶å"ã€"æœ€å"æ˜¯è‡ªç„¶æ–­ç‚¹ï¼‰
        - ä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µåè¯ä¿æŒå®Œæ•´
        - æ•°å­—ã€å…¬å¼ã€ä»£ç ç‰‡æ®µä¸è¦ä»ä¸­é—´æ–­å¼€
        - å› æœå…³ç³»å¥å¯ä»¥ç¨é•¿ï¼Œä¿æŒé€»è¾‘å®Œæ•´æ€§
      

# é»˜è®¤åœºæ™¯ï¼ˆæ— æ³•åˆ¤æ–­æ—¶ä½¿ç”¨ï¼‰
default_scene: "chatting"

```
è¯·ä½ è€ƒè™‘æˆ‘ä»¬æ­¤å‰æè¿°çš„å†…å®¹ï¼Œç¡®å®šè¿™éƒ¨åˆ†æˆ‘ä»¬åˆ†åˆ«è¦ä¸ºæ¯ä¸ªåœºæ™¯åšæ€æ ·çš„åˆ†è¯é¢å¤–æç¤ºï¼ˆä¾ç„¶æ³¨æ„æ­¤é˜¶æ®µåŸåˆ™ï¼šä¸æ”¹å˜å†…å®¹ï¼Œä»…å°†åŸæœ¬asrå¯èƒ½é›¶ç¢æˆ–è€…å¤§æ®µçš„æ–‡æœ¬åšå‡ºæ°å½“é•¿åº¦ã€è¯­æ³•ç»“æ„ã€ä¹ æƒ¯çš„åˆ†è¯ï¼‰ã€‚

ä¸Šè¿°ç¤ºä¾‹å†…å®¹å¯ä»¥ä¿®æ”¹ã€‚

é¦–å…ˆå¯¹ä½ç½®ä¸€åšå‡ºä¿®æ”¹å»ºè®®ï¼Œç„¶åå¯¹ä½ç½®äºŒå„ä¸ªæƒ…æ™¯ç»™å‡ºè®¨è®º

---

## ç¯èŠ‚ 2ï¼šå­—å¹•ä¼˜åŒ–ï¼ˆOptimizeï¼‰é˜¶æ®µ


æ³¨æ„ï¼Œæ­¤å¤„å¯¹äºè¯­è¨€çš„å‡è®¾å’Œä¹‹å‰ä¸€æ ·ï¼Œä»ç„¶é»˜è®¤æ˜¯æ—¥è¯­ç›´æ’­çš„è½¬å½•å­—å¹•

ä¸‹è¿°ç¯èŠ‚åœ¨ä»£ç ä¸­çš„è°ƒç”¨å¦‚ä¸‹ï¼š

```python

    def _optimize_subtitle(self, asr_data: ASRData) -> ASRData:
        """
        å†…éƒ¨æ–¹æ³•ï¼šä¼˜åŒ–å­—å¹•å†…å®¹
        å¤ç”¨ BaseTranslator çš„å¹¶å‘æ¡†æ¶
        """
        assert asr_data is not None, "è°ƒç”¨å¥‘çº¦é”™è¯¯: asr_data ä¸èƒ½ä¸ºç©º"
        
        if not asr_data.segments:
            logger.warning("å­—å¹•å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ä¼˜åŒ–")
            return asr_data

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        subtitle_dict = {str(i): seg.text for i, seg in enumerate(asr_data.segments, 1)}
        
        # åˆ†æ‰¹å¤„ç†ï¼ˆä½¿ç”¨åŸºç±»çš„æ‰¹é‡å¤§å°ï¼‰
        items = list(subtitle_dict.items())
        chunks = [
            dict(items[i : i + self.batch_num])
            for i in range(0, len(items), self.batch_num)
        ]

        # å¹¶è¡Œä¼˜åŒ–ï¼ˆå¤ç”¨çº¿ç¨‹æ± ï¼‰
        optimized_dict: Dict[str, str] = {}
        futures = []
        
        if not self.executor:
            raise ValueError("çº¿ç¨‹æ± æœªåˆå§‹åŒ–")
        
        for chunk in chunks:
            future = self.executor.submit(self._optimize_chunk, chunk)
            futures.append((future, chunk))

        # æ”¶é›†ç»“æœ
        for future, chunk in futures:
            if not self.is_running:
                break
            try:
                result = future.result()
                optimized_dict.update(result)
            except Exception as e:
                logger.error(f"ä¼˜åŒ–æ‰¹æ¬¡å¤±è´¥: {e}")
                optimized_dict.update(chunk)  # å¤±è´¥æ—¶ä¿ç•™åŸæ–‡

        # éªŒè¯æ•°é‡ä¸€è‡´æ€§
        assert len(optimized_dict) == len(subtitle_dict), \
            f"é€»è¾‘é”™è¯¯: ä¼˜åŒ–åå­—å¹•æ•°é‡ ({len(optimized_dict)}) ä¸åŸæ–‡æ•°é‡ ({len(subtitle_dict)}) ä¸ä¸€è‡´"

        # åˆ›å»ºæ–° segments
        new_segments = [
            ASRDataSeg(
                text=optimized_dict.get(str(i), seg.text),
                start_time=seg.start_time,
                end_time=seg.end_time,
                translated_text=seg.translated_text
            )
            for i, seg in enumerate(asr_data.segments, 1)
        ]
        
        assert len(new_segments) == len(asr_data.segments), \
            f"é€»è¾‘é”™è¯¯: ç”Ÿæˆçš„ segments æ•°é‡ ({len(new_segments)}) ä¸åŸæ–‡æ•°é‡ ({len(asr_data.segments)}) ä¸ä¸€è‡´"
        
        return ASRData(new_segments)

    def _optimize_chunk(self, subtitle_chunk: Dict[str, str]) -> Dict[str, str]:
        """
        ä¼˜åŒ–å•ä¸ªå­—å¹•æ‰¹æ¬¡
        ä½¿ç”¨ Agent Loop è‡ªåŠ¨éªŒè¯å’Œä¿®æ­£
        """
        start_idx = next(iter(subtitle_chunk))
        end_idx = next(reversed(subtitle_chunk))
        logger.debug(f"æ­£åœ¨ä¼˜åŒ–å­—å¹•ï¼š{start_idx} - {end_idx}")
        
        prompt = get_prompt("optimize/subtitle")
        
        user_prompt = (
            f"Correct the following subtitles. Keep the original language, do not translate:\n"
            f"<input_subtitle>{json.dumps(subtitle_chunk, ensure_ascii=False)}</input_subtitle>"
        )

        if self.optimize_prompt:
            user_prompt += f"\nReference content:\n<reference>{self.optimize_prompt}</reference>"

        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_prompt},
        ]

        last_result = subtitle_chunk
        
        # Agent Loop
        for step in range(self.MAX_STEPS):
            try:
                response = call_llm(messages=messages, model=self.model, temperature=0.2)
                
                result_text = response.choices[0].message.content
                if not result_text:
                    raise ValueError("LLMè¿”å›ç©ºç»“æœ")
                
                result_dict = json_repair.loads(result_text)
                if not isinstance(result_dict, dict):
                    raise ValueError(f"LLMè¿”å›ç»“æœç±»å‹é”™è¯¯ï¼ŒæœŸæœ›dictï¼Œå®é™…{type(result_dict)}")
                
                last_result = result_dict
                
                # éªŒè¯ç»“æœ
                is_valid, error_message = self._validate_optimization_result(
                    original_chunk=subtitle_chunk,
                    optimized_chunk=result_dict
                )
                
                if is_valid:
                    return result_dict
                
                # éªŒè¯å¤±è´¥ï¼Œæ·»åŠ åé¦ˆ
                logger.warning(f"ä¼˜åŒ–éªŒè¯å¤±è´¥ï¼Œå¼€å§‹åé¦ˆå¾ªç¯ (ç¬¬{step + 1}æ¬¡å°è¯•): {error_message}")
                messages.append({"role": "assistant", "content": result_text})
                messages.append({
                    "role": "user",
                    "content": f"Validation failed: {error_message}\n"
                              f"Please fix the errors and output ONLY a valid JSON dictionary.DO NOT REPLY ANY ADDITIONEL EXPLANATION OR OTHER PREVIOUS TEXT."
                })
                
            except Exception as e:
                logger.warning(f"ä¼˜åŒ–æ‰¹æ¬¡å°è¯• {step+1} å¤±è´¥: {e}")
                if step == self.MAX_STEPS - 1:
                    return last_result
        
        return last_result

    def _validate_optimization_result(
        self, original_chunk: Dict[str, str], optimized_chunk: Dict[str, str]
    ) -> Tuple[bool, str]:
        """éªŒè¯ä¼˜åŒ–ç»“æœ"""
        expected_keys = set(original_chunk.keys())
        actual_keys = set(optimized_chunk.keys())

        # æ£€æŸ¥é”®åŒ¹é…
        if expected_keys != actual_keys:
            missing = expected_keys - actual_keys
            extra = actual_keys - expected_keys
            error_parts = []
            
            if missing:
                error_parts.append(f"Missing keys: {sorted(missing)}")
            if extra:
                error_parts.append(f"Extra keys: {sorted(extra)}")

            error_msg = (
                "\n".join(error_parts) + f"\nRequired keys: {sorted(expected_keys)}\n"
                f"Please return the COMPLETE optimized dictionary with ALL {len(expected_keys)} keys."
            )
            return False, error_msg

        # æ£€æŸ¥æ”¹åŠ¨æ˜¯å¦è¿‡å¤§
        excessive_changes = []
        for key in expected_keys:
            original_text = original_chunk[key]
            optimized_text = optimized_chunk[key]

            original_cleaned = re.sub(r"\s+", " ", original_text).strip()
            optimized_cleaned = re.sub(r"\s+", " ", optimized_text).strip()

            matcher = difflib.SequenceMatcher(None, original_cleaned, optimized_cleaned)
            similarity = matcher.ratio()
            similarity_threshold = 0.3 if count_words(original_text) <= 10 else 0.5

            if similarity < similarity_threshold:
                excessive_changes.append(
                    f"Key '{key}': similarity {similarity:.1%} < {similarity_threshold:.0%}. "
                    f"Original: '{original_text}' â†’ Optimized: '{optimized_text}'"
                )

        if excessive_changes:
            error_msg = ";\n".join(excessive_changes)
            error_msg += (
                "\n\nYour optimizations changed the text too much. "
                "Keep high similarity (â‰¥70% for normal text) by making MINIMAL changes."
            )
            return False, error_msg

        return True, ""

```


### ä½ç½® 1ï¼šä¼˜åŒ–æç¤ºè¯æ¨¡æ¿
**æ¨¡æ¿æ–‡ä»¶**ï¼š`vat/llm/prompts/optimize/subtitle.md`

#### ä½œç”¨
åœ¨ç¿»è¯‘å‰ä¿®æ­£åŸè¯­è¨€å­—å¹•çš„é”™åˆ«å­—ã€è¯­éŸ³è¯†åˆ«é”™è¯¯ã€å»é™¤æ— æ„ä¹‰å£ç™–ï¼ˆum/uh/ahï¼‰ã€æ— æ„ä¹‰æ‹Ÿå£°è¯ï¼ˆé‡å¤çš„å•Šå•Šå•Š->å•Šâ€”â€”ï¼‰ã€ç»Ÿä¸€æœ¯è¯­ã€‚

#### å½“å‰æ¨¡æ¿æ ¸å¿ƒè§„åˆ™

```markdown
You are a professional subtitle correction expert. Your task is to fix errors in video subtitles while preserving the original meaning and structure.

<context>
Subtitles often contain recognition errors, filler words, and formatting inconsistencies that reduce readability. Your corrections should maintain the original expression while fixing technical errors and improving clarity.
</context>

<input_format>
You will receive:

1. A JSON object with numbered subtitle entries
2. Optional reference information containing:
   - Content context
   - Important terminology
   - Specific correction requirements
</input_format>

<instructions>
1. Fix errors while preserving original sentence structure (no paraphrasing or synonyms)
2. Remove filler words and non-verbal sounds: um, uh, ah, laughter markers, coughing sounds, etc.
3. Standardize formatting:
   - Correct punctuation
   - Proper English capitalization
   - Mathematical formulas in plain text (use Ã—, Ã·, =, etc.)
   - Code syntax (variable names, function calls)
4. Maintain subtitle numbering (no merging or splitting entries)
5. Use reference information to correct terminology when provided
6. Keep original language (English stays English, Chinese stays Chinese)
7. Output only the corrected JSON, no explanations
</instructions>

<output_format>
Return a pure JSON object with corrected subtitles:

{
"0": "[corrected subtitle]",
"1": "[corrected subtitle]",
...
}

Do not include any commentary, explanations, or markdown formatting.
</output_format>

<examples>

<example>
<input_subtitles>
{
  "0": "the formula is ah x squared plus y squared equals uh z squared",
  "1": "this is called the pathagrian theorem *laughs*",
  "2": "it's um used in geometry and trigonomatry"
}
</input_subtitles>
<reference>
Content: Mathematics - Pythagorean theorem
Terms: Pythagorean theorem, geometry, trigonometry
</reference>
<output>
{
  "0": "The formula is xÂ² + yÂ² = zÂ²",
  "1": "This is called the Pythagorean theorem",
  "2": "It's used in geometry and trigonometry"
}
</output>
</example>

<example>
<input_subtitles>
{
  "0": "å¤§å®¶å¥½å‘ƒä»Šå¤©æˆ‘ä»¬æ¥å­¦ä¹ æœºå™¨å­¦ä¹ ",
  "1": "é¦–å…ˆä»‹ç»ä¸€ä¸‹ç¥ç»ç½‘ç»œçš„å‡ æœ¬æ¦‚å¿µ",
  "2": "å®ƒä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•æ¥è®­ç»ƒæ¨¡å‹å—¯"
}
</input_subtitles>
<reference>
Content: æœºå™¨å­¦ä¹ åŸºç¡€
Terms: æœºå™¨å­¦ä¹ , ç¥ç»ç½‘ç»œ, åå‘ä¼ æ’­ç®—æ³•
</reference>
<output>
{
  "0": "å¤§å®¶å¥½,ä»Šå¤©æˆ‘ä»¬æ¥å­¦ä¹ æœºå™¨å­¦ä¹ ",
  "1": "é¦–å…ˆä»‹ç»ä¸€ä¸‹ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µ",
  "2": "å®ƒä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•æ¥è®­ç»ƒæ¨¡å‹"
}
</output>
</example>
</examples>

<critical_notes>

- Preserve meaning and structure - only fix errors
- Use reference information to correct misrecognized terms
- Output pure JSON only, no explanations or markdown
- Maintain original language throughout
  </critical_notes>

```

é‚£ä¹ˆï¼Œè¿™ä¸€é˜¶æ®µï¼Œå°±æ˜¯éå¸¸å…³é”®çš„ç¯èŠ‚äº†ï¼šå‰é¢æˆ‘ä»¬çš„å­—å¹•æ˜¯asrä»ç›´æ’­è§†é¢‘ä¸­æå–çš„ï¼Œé‚£ä¹ˆåŠ¿å¿…å­˜åœ¨å¾ˆå¤šè¯¯æŠ¥æ¼æŠ¥ã€‚
æ¯”å¦‚æˆ‘ä¸¾å‡ ä¸ªæˆ‘è§‚å¯Ÿåˆ°çš„ç»å…¸é—®é¢˜ï¼š
- æ¼å­—ï¼šæ—¥è¯­å®¹æ˜“è¿è¯»ï¼Œå¯èƒ½ç¼ºå¤±å­—ç¬¦
- é”™è¯ï¼šè¯†åˆ«å‡ºçš„ç»“æœä»å­—é¢ä¸Šçœ‹æ˜¯å¯¹çš„ï¼Œä½†æ˜¯å…¶ä¸ç¬¦åˆä¸Šä¸‹æ–‡è¯­å¢ƒï¼šæ¯”å¦‚ä¸»æ’­æ˜¯ç™½ä¸Šå¹é›ªï¼ˆshirakami fubukiï¼‰ï¼Œé‚£ä¹ˆå¥¹è‡ªç§°è‡ªå·±çš„æ—¶å€™å°±æœ‰å¯èƒ½è¢«è¯†åˆ«æˆâ€œç™½å‘â€â€œç™½è‰²â€ã€‚å¯¼è‡´â€œasræ²¡é”™ã€translateä¹Ÿæ²¡é”™ï¼Œä½†æ˜¯ç»“æœè´¨é‡å°±æ˜¯å¾ˆå·®â€çš„é—®é¢˜ã€‚ç±»ä¼¼çš„ï¼Œè¿˜æœ‰å¥¹å¯¹äºç²‰ä¸ç¾¤ä½“çš„ç§°å‘¼sukonbuä¹Ÿå®¹æ˜“è¢«é”™è¯¯è¯†åˆ«ç„¶åé”™è¯¯çš„ç¿»è¯‘â€”â€”å¹¶ä¸”æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬æ— è®ºå¦‚ä½•éƒ½æ˜¯ä¸å¯èƒ½ç©·å°½æ‰€æœ‰çš„ä¸“æœ‰è¯æ±‡çš„æ­£ç¡®ç¿»è¯‘å½¢å¼çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥ä¸¾å‡ ä¸ªä»£è¡¨æ€§çš„ã€ä¸å¯èƒ½è¢«llmæ€è€ƒè”ç³»åˆ°çš„ä¾‹å­ï¼ˆæ¯”å¦‚ç™½ä¸Šè¿™ä¸ªä¸»æ’­å¯¹äºç²‰ä¸çš„ç§°å‘¼ï¼Œåªèƒ½æˆ‘ä»¬å…ˆéªŒçš„æŒ‡å®šï¼‰ã€‚ç„¶åï¼Œé€šè¿‡æç¤ºè¯è¯´æ˜ï¼Œè¦æ±‚ä»–å¤šæ€è€ƒï¼Œå°½å¯èƒ½å°†ç›¸è¿‘çš„ã€è¯»éŸ³å¯èƒ½æœ‰å°å¹…åº¦å·®åˆ«çš„åŸæ–‡å­—å¹•åœ¨ä¸Šä¸‹æ–‡è¯­å¢ƒä¸­çµæ´»åˆ¤æ–­ã€‚ï¼ˆæ¯”å¦‚æè¿°è¿™ä¸ªæƒ…æ™¯ï¼Œç„¶åè¦æ±‚ç»“åˆæˆ‘ä»¬çš„ä¾‹å­ï¼Œçµæ´»æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼Œä¸è¦æœºæ¢°çš„passï¼‰
- é”™å­—ï¼šå’Œä¸Šé¢çš„é”™è¯ç±»ä¼¼ï¼Œä½†æ˜¯ä¸åŒäºå®ƒçš„æ˜¯ï¼Œè¿™é‡ŒæŒ‡çš„æ˜¯å¯¹äºéä¸“æœ‰è¯æ±‡/ç§°å‘¼çš„è¯¯æŠ¥ã€‚æ¯”å¦‚ä¸¤ä¸ªåœ¨æ—¥è¯­ä¸­è¯»éŸ³ç›¸è¿‘çš„å‡åè¯æ±‡ï¼ˆvrchatå’Œæ²³è±šxxxï¼‰ï¼Œå¯èƒ½è¢«é”™è¯¯çš„è¯†åˆ«ã€‚å°½ç®¡è¿™ä¸ªå¯ä»¥åœ¨ä¸‹æ–‡ç¿»è¯‘æ—¶çº æ­£ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿè¦å°½å¯èƒ½åœ¨è¿™é‡Œæ”¹å˜æ­£ç¡®ã€‚è¿˜æœ‰ä¸€ç§æƒ…å†µï¼Œå°±æ˜¯è¯»éŸ³ç›¸åŒï¼Œä½†æ˜¯å†™æ³•ä¸åŒï¼ˆæ¯”å¦‚å¹³ã€ç‰‡å‡åå’Œæ±‰å­—å†™æ³•ï¼Œå¯èƒ½ä¸€ä¸ªè¯»éŸ³å¯¹åº”äº”å…­ç§æ–‡å­—è¡¨è¾¾ï¼Œä½†æ˜¯æ˜¾ç„¶åªæœ‰ä¸€ä¸¤ç§çš„æ„æ€æ˜¯å¯¹çš„ï¼‰ã€‚æ‰€ä»¥è¿™é‡Œä¹Ÿè¦è¦æ±‚llmçµæ´»ç»“åˆè¯­å¢ƒï¼Œåˆ¤åˆ«å‡ºâ€œçœ‹èµ·æ¥å’Œä¸Šä¸‹æ–‡å¯¹ä¸ä¸Šâ€çš„è¯åˆ°åº•æ˜¯ä¸æ˜¯è¯¯æŠ¥ï¼Ÿæœ‰æ²¡æœ‰å¿…è¦ä¿®æ”¹æˆä»€ä¹ˆå…¶ä»–çš„è¯æ±‡ï¼Ÿä½†æ˜¯è¿™é‡Œè¦ç‰¹åˆ«è°¨æ…â€”â€”æ¯”å¦‚å¯èƒ½ä¸Šä¸‹æ–‡æ˜¯åœ¨è®²æ¸¸æˆåšé¥­ï¼Œç„¶åæåˆ°äº†æ²³è±šâ€”â€”è¿™ä¸ªæ—¶å€™è™½ç„¶å¯èƒ½çœ‹èµ·æ¥çªå…€ï¼Œå‡ºç°äº†ä¸€ä¸ªæ²¡è§è¿‡çš„è¯æ±‡ï¼Œä½†æ˜¯æœªå¿…ä¸æ˜¯æ­£ç¡®çš„ã€‚ç±»ä¼¼çš„ï¼Œåœ¨æ‰“æ¸¸æˆçš„æ—¶å€™æåˆ°vrchatä¹Ÿæ˜¯å¾ˆåˆç†çš„ã€‚æ‰€ä»¥åˆ°åº•è¦ä¸è¦ä¿®æ”¹ï¼Ÿè¿™ä¸ªå°±ä¸èƒ½åªçœ‹ä¸€ä¸¤å¥è¯æ˜¯ä¸Šä¸‹æ–‡æ¥åˆ¤æ–­ã€‚è€Œæ˜¯åº”è¯¥ç»“åˆè¿™æ¬¡è¾“ç»™å¤§æ¨¡å‹çš„æ•´ä¸ªä¸Šä¸‹æ–‡ï¼Œæ¥åˆ¤æ–­æŸä¸ªå¯ç–‘çš„è¯æ±‡åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€ã€‚æ­¤å¤–ï¼Œå› ä¸ºä»£ç é‡Œé¢ä¼šæ£€æŸ¥ä¿®æ”¹ç‡ï¼Œé˜²æ­¢å¤§æ¨¡å‹â€œæŠ½é£â€ï¼Œæ‰€ä»¥åœ¨ä¿®æ”¹çš„æ—¶å€™ï¼Œæœ€å¥½ä¿æŒåŸæœ‰çš„å†™æ³•ï¼ˆæ¯”å¦‚åŸæœ¬æ˜¯ç‰‡å‡åçš„æŸä¸ªå¤–æ¥è¯ï¼Œllmç¡®å®šæ˜¯è¯¯æŠ¥ï¼Œè¦ä¿®æ”¹ï¼Œé‚£ä¹ˆå¦‚æœè¿™ä¸ªä¿®æ”¹çš„ç»“æœç¡®å®æŸç§è¡¨ç¤ºï¼ˆå‡åï¼Ÿæ±‰å­—ï¼Ÿï¼‰çœ‹èµ·æ¥å’ŒåŸæœ¬çš„å­—ç¬¦å¾ˆç±»ä¼¼ï¼Œé‚£ä¹ˆè¿˜æ˜¯æœ€å¥½å¯¹é½ä¸€ä¸‹ï¼Œä¸è¦å½»åº•é‡å†™ã€‚å¯¹äºè¯­å¥ç»“æ„çš„é‡å†™æˆ‘ä»¬æ”¾åœ¨æœ€åçš„translateç¯èŠ‚ï¼Œè€Œä¸æ˜¯è¿™é‡Œï¼‰


### ä½ç½® 2ï¼šä¼˜åŒ–è‡ªå®šä¹‰æç¤ºè¯ï¼ˆé…ç½®ï¼‰
**é…ç½®å­—æ®µ**ï¼š`config/default.yaml` â†’ `translator.llm.optimize.custom_prompt`

```yaml
translator:
  llm:
    optimize:
      enable: true
      custom_prompt: ""  # åœ¨è¿™é‡Œå¡«å…¥æœ¯è¯­è¡¨ã€ä¸»æ’­ç‰¹ç‚¹ã€å¸¸è§é”™è¯¯çº æ­£è§„åˆ™
```

è¿™é‡Œï¼Œå°±æ˜¯è¦å¡«å…¥æˆ‘ä»¬ä¸Šé¢è®¨è®ºçš„ï¼šspecify ä¸»æ’­ï¼ˆç¿»è¯‘åœºæ™¯ï¼‰çš„æç¤ºè¯äº†ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸Šé¢åº”è¯¥æŒ‡å®šâ€œä½ è¦æ ¹æ®xxå»è”ç³»ä¸Šä¸‹æ–‡çµæ´»åˆ¤æ–­â€è€Œè¿™é‡Œå°±æ˜¯â€œåˆ°åº•è¿™ä¸ªä¸»æ’­æ˜¯ä»€ä¹ˆï¼Œæœ‰ä»€ä¹ˆçº¦å®šçš„ç§°å‘¼â€œä¹‹ç±»çš„åœºæ™¯ç‰¹å®šæç¤ºè¯ã€‚

è¿™é‡Œçš„ä»£ç ä¸­åº”ç”¨å½¢å¼å¦‚ä¸‹ï¼š

```python
        self.optimize_prompt = custom_optimize_prompt

â€¦â€¦â€¦â€¦
        if self.optimize_prompt:
            user_prompt += f"\nReference content:\n<reference>{self.optimize_prompt}</reference>"

        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_prompt},
        ]
```

å³ï¼Œå¡«åœ¨æœ€å¼€å§‹çš„user promptæœ«å°¾

æˆ‘ä»¬è¿™é‡Œä»¥å‰é¢ä¸¾çš„ä¾‹å­ï¼ˆç™½ä¸Šå¹é›ªï¼‰æ¥å®Œæˆè¿™éƒ¨åˆ†çš„æç¤ºè¯ç¼–å†™

è¿™é‡Œè¯·ä½ å¤šæ£€ç´¢ä¸€ä¸‹å¥¹çš„ç›¸å…³æ¨æ–‡ã€æ–‡æ¡ˆã€è§†é¢‘ã€ä»‹ç»ç­‰ã€‚å°½å¯èƒ½çµæ´»ã€å…¨é¢ã€å¯Œæœ‰ä»£è¡¨æ€§çš„ç¼–å†™è¿™ä¸ªæç¤ºè¯

ï¼ˆæ³¨æ„ï¼Œæˆ‘ä»¬äº¤æµçš„æ—¶å€™è¿˜æ˜¯ç”¨ä¸­æ–‡ã€‚æœ€åå®šç¨¿å†ç¿»è¯‘æˆllmæ¯”è¾ƒå¥½æ¥å—çš„è‹±æ–‡ï¼‰

åé¢æˆ‘ä»¬è¿˜è¦é’ˆå¯¹å…·ä½“ç›´æ’­çš„é¢˜æç¼–å†™ç‰¹å®šçš„é¢å¤–æç¤ºè¯ã€‚ä¸è¿‡é‚£ä¸ªæ˜¯ä¸‹ä¸€é˜¶æ®µçš„ä»»åŠ¡

### ä½ç½® 3ï¼šåœºæ™¯ç‰¹å®šçš„ä¼˜åŒ–æç¤ºè¯ï¼ˆæ–°å¢ï¼‰
**é…ç½®æ–‡ä»¶**ï¼š`vat/llm/scenes.yaml` â†’ `scenes[i].prompts.optimize`

ç±»ä¼¼äºæ–­å¥ï¼Œæ¯ä¸ªåœºæ™¯ä¹Ÿå¯é…ç½®ç‹¬ç«‹çš„ä¼˜åŒ–æç¤ºè¯ã€‚æ‰§è¡Œæµç¨‹ä¸æ–­å¥ç›¸åŒï¼Œåœºæ™¯ä¼˜åŒ–æç¤ºè¯ä¼šä¸å…¨å±€æç¤ºè¯åˆå¹¶åä½¿ç”¨ã€‚

#### ç¤ºä¾‹ï¼šé—²èŠç›´æ’­çš„ä¼˜åŒ–è§„åˆ™
```yaml
scenes:
  - id: "chatting"
    name: "é—²èŠç›´æ’­"
    prompts:
      optimize: |
        ## é—²èŠç›´æ’­ä¼˜åŒ–è§„åˆ™
        - ä¿ç•™æ‰€æœ‰è¯­æ°”è¯å’Œå£ç™–ï¼ˆ"å“ˆ"ã€"å—¯"ã€"å‘¢"ã€"å•¦"ï¼‰
        - å¯¹è§‚ä¼—çš„ç§°å‘¼è¦å¤šæ ·åŒ–ï¼ˆ"å¤§å®¶"ã€"å„ä½"ã€"æœ‹å‹ä»¬"ï¼‰
        - ä¿ç•™é‡å¤è¯å¼ºè°ƒæƒ…ç»ªï¼ˆ"å¥½å¥½å¥½"ã€"å¯¹å¯¹å¯¹"ï¼‰
        - åˆ é™¤æ˜æ˜¾çš„ fillerï¼š"å•Š"ï¼ˆçŠ¹è±«è¯ï¼‰ä½†ä¿ç•™"å•Š"ï¼ˆæƒŠè®¶ï¼‰
```

---

## ç¯èŠ‚ 3ï¼šç¿»è¯‘ï¼ˆTranslateï¼‰é˜¶æ®µ

å› ä¸ºè¿™ä¸ªç¿»è¯‘æ˜¯æ•´ä¸ªæµç¨‹æœ€åçš„ç¯èŠ‚äº†ï¼ˆè¾“å‡ºå°†ä¼šç›´æ¥æ‹¿å»åµŒå…¥è§†é¢‘ï¼‰ï¼Œæ‰€ä»¥è¿™ä¸ªåœ°æ–¹çš„ä¼˜åŒ–å¯ä»¥ç¨å¾®æ¿€è¿›ä¸€ç‚¹â€”â€”æ¯”å¦‚ï¼Œä¸­æ—¥è¯­è¨€çš„ç»“æ„è¯­æ³•æ˜¾ç„¶ä¸åŒï¼Œæ‰€ä»¥å¿…ç„¶æœ‰è¯­å¥çš„é‡æ„ï¼ˆè¿™ä¸ªå‡ ä¹éƒ½ä¸ç”¨å¼ºè°ƒäº†ï¼Œæ˜¯é»˜è®¤çš„ï¼‰ï¼Œç„¶ååœ¨ç¿»è¯‘çš„æ—¶å€™ï¼Œä¸€æ–¹é¢è¦æ¿€è¿›çš„ã€å®Œå…¨çš„çº æ­£é”™åˆ«å­—ï¼ˆå³ï¼Œæˆ‘ä»¬åœ¨ä¸Šæ–‡optimzedé˜¶æ®µå°±å°è¯•è¿‡äº†çº æ­£â€œasræ²¡é”™ï¼Œå•è¯æ²¡é”™ï¼Œä½†æ˜¯ä¸ç¬¦åˆè¯­å¢ƒâ€çš„æƒ…å†µï¼Œå¹¶ä¸”åœ¨ä½ ç»™å‡ºäº†å‡ ç‰ˆä¼˜åŒ–ä¹‹åä¾ç„¶å­˜åœ¨é—®é¢˜ï¼ˆæ¯”å¦‚ç™½ä¸Šå¹é›ªè‡ªç§°è¢«è¯†åˆ«ä¸ºç™½å‘ç­‰ï¼‰ã€‚é‚£ä¹ˆï¼Œåœ¨è¿™ä¸ªæœ€åçš„ç¿»è¯‘é˜¶æ®µï¼Œæˆ‘ä»¬å°±éœ€è¦è¦æ±‚llmå¼ºéµå¾ªæˆ‘ä»¬çš„custom promptï¼ŒæŠŠæ‰€æœ‰çœ‹èµ·æ¥è¿™ç§å¯ç–‘çš„ã€ä¸è‡ªç„¶çš„ã€ä¸ç¬¦åˆè¯­å¢ƒçš„å†…å®¹éƒ½åšæ›¿æ¢å’Œä¼˜åŒ–â€”â€”è¿™ä¸ªåœ°æ–¹ç”šè‡³å¯ä»¥ä¸ºäº†æ³¨é‡ä¸Šä¸‹æ–‡çš„è¿è´¯è‡ªç„¶ï¼Œä»¥åŠæˆ‘ä¸‹é¢å¼ºè°ƒçš„ç¿»è¯‘é£æ ¼ï¼Œè€Œç¨å¾®çš„æœ‰ä¸€äº›rewriteã€‚

custom prompté‡Œé¢ï¼Œæ³¨æ„ç¿»è¯‘çš„é£æ ¼ï¼šæˆ‘ä»¬ç°åœ¨è¿˜æ˜¯ä»¥ä¸»æ’­ç™½ä¸Šå¹é›ªä¸ºä¾‹ï¼Œåº”è¯¥è€ƒè™‘åˆ°å¥¹çš„é£æ ¼æ˜¯åå‘æ´»æ³¼å¯çˆ±çš„
æ¯”å¦‚â€”â€”â€œãˆãƒ¼â€è¿™ç§ç¿»è¯‘å°±ä¸åº”è¯¥æ˜¯â€œé¢â€æˆ–è€…â€œå‘ƒâ€è¿™ç§ï¼Œè€Œæ˜¯åº”è¯¥ç¿»è¯‘æˆâ€œè¯¶â€”â€”â€æˆ–è€…â€œå‘œ!â€"å‘œ~"è¿™ç§â€”â€”æ€»è€Œè¨€ä¹‹ï¼Œåº”è¯¥çœ‹èµ·æ¥ç½‘ç»œé£ã€å£è¯­åŒ–ã€æ´»æ³¼å¯çˆ±ï¼Œ**ç¬¦åˆç»å…¸çš„vtuberâ€œæ¸…æ¥šç³»â€çš„å½¢è±¡**ã€‚è€Œä¸”ï¼Œ**æ³¨æ„ä¸è¦å’Œç®€ä¸­äº’è”ç½‘nativeçš„æ··æ·†**â€”â€”æ¯”å¦‚ç®€ä¸­çš„å¥³æ€§å¯èƒ½ç»å¸¸è¯´ä»€ä¹ˆâ€œå®å­ä»¬xxxâ€è¿™ç§ï¼Œä½†æ˜¯è¿™ç§è¡¨è¾¾åœ¨æ—¥è¯­ä¸»æ’­ä¸­æ˜¯ä¸å­˜åœ¨çš„ï¼Œå¹¶ä¸”ä¹Ÿæ˜¾å¾—å¾ˆå°´å°¬ï¼Œå¾ˆä¸è‡ªç„¶ã€‚æ‰€ä»¥â€œè¦ç¿»è¯‘æˆnativeçš„ä¸­æ–‡â€ï¼Œä½†æ˜¯è¿™æ›´å¤šçš„æ˜¯æŒ‡è¯­æ³•ã€ç»“æ„ç­‰ã€‚è€Œå…·ä½“çš„ä¸€äº›åè¯ã€å£è¯­ã€ä¿—è¯­ã€å–èŒä¹‹ç±»çš„è¡¨è¾¾ä¾ç„¶åº”è¯¥ä¿æŒäºŒæ¬¡å…ƒæƒ¯ç”¨/æ—¥è¯­çš„é£æ ¼ï¼Œä¸è¦å’Œç®€ä¸­äº’è”ç½‘ä¸Šæ•…ä½œgeekã€å¥³æƒã€è€½ç¾ä¹‹ç±»çš„æ¶ä¿—é£æ ¼æ··æ·†ã€‚å¦‚æœä¸€å®šè¦å½’ç±»ä¸€ä¸ªé£æ ¼ï¼Œåº”è¯¥è¯´æ˜¯â€œè¿‘å¹´ä½†åæ—©ä¸€ç‚¹çš„äºŒæ¬¡å…ƒã€æ—¥æœ¬çš„å°‘å¥³ç³»ã€hololiveã€Vtuberä¸»æ’­â€çš„æ„Ÿè§‰

æ­¤å¤–ï¼Œä¸€äº›æ˜æ˜¾æ˜¯æ‹Ÿå£°è¯ã€æ„Ÿå¹è¯ã€æ— æ„ä¹‰çš„å£è¯­ã€å£ç™–ç­‰ï¼Œåº”è¯¥ç¿»è¯‘æˆå¯çˆ±çš„ï¼Œå°‘å¥³çš„ï¼Œç•¥å¸¦ä¸€äº›å–èŒæ„Ÿè§‰çš„è¡¨è¾¾ï¼Œå¹¶ä¸”å¯¹äºå¤§é‡çš„é‡å¤è¯ï¼ˆãˆãˆãˆãˆã€ã¯ã¯ã¯ã¯ã€ã»ã„ã»ã„ã€ã§ã§ã§ä¹‹ç±»çš„ï¼‰ï¼Œåº”è¯¥æ°å½“çš„ç¼©å‡åˆå¹¶ï¼Œçµæ´»è€ƒè™‘å˜æˆå£è¯­ä¸Šç±»ä¼¼ï¼Œä½†æ˜¯å­—å¹•ä¸­ä¸ä¼šçœ‹èµ·æ¥å¾ˆå¥‡æ€ªçš„è¡¨è¾¾ã€‚è¿™ä¸ªé˜¶æ®µçš„é‡å†™å¹…åº¦å¯ä»¥æ˜¯æ¯”è¾ƒå¤§çš„ã€‚

åœ¨å…¨å±€çš„ç¿»è¯‘æç¤ºè¯ä¸­ï¼Œå¯ä»¥ä¸ç”¨å¤ªå¼ºè°ƒâ€œæ—¥ç³»ã€å¯çˆ±â€ä¹‹ç±»çš„ç‰¹ç‚¹ï¼Œä½†æ˜¯ä¹Ÿä¾ç„¶è¦é¿å…æˆ‘ä¸Šè¿°è¯´çš„ï¼Œç®€ä¸­äº’è”ç½‘ä¸Šä¸€äº›æ¯”è¾ƒæ¶ä¿—çš„é£æ ¼ã€‚


é‚£ä¹ˆä½ ç°åœ¨çš„ä»»åŠ¡å’Œä¹‹å‰ç±»ä¼¼ï¼Œä¾ç„¶æ˜¯é¦–å…ˆï¼ŒæŠŠç¿»è¯‘é˜¶æ®µçš„æ•´ä½“æç¤ºè¯æ¨¡æ¿åšè°ƒæ•´ï¼ˆå…ˆä¸æˆ‘æ²Ÿé€šè¦æ€ä¹ˆæ”¹ï¼‰ã€‚
ç„¶åï¼Œç»™å‡ºé’ˆå¯¹ç™½ä¸Šå¹é›ªè¿™ä¸ªcustom æƒ…æ™¯çš„æç¤ºè¯ã€‚ï¼ˆå¯ä»¥æ³¨æ„åˆ°ï¼Œsenceæç¤ºè¯æˆ‘ä»¬å¯¹äºoptimizedå’Œtranslateä¸¤ä¸ªé˜¶æ®µéƒ½è¿˜æ²¡æœ‰å†™â€”â€”è¿™ä¸ªæˆ‘ä»¬ä¹‹åå†å¤„ç†ï¼‰



### ä½ç½® 1ï¼šç¿»è¯‘æç¤ºè¯æ¨¡æ¿

#### æ¨¡æ¿ Aï¼šæ ‡å‡†ç¿»è¯‘
**æ¨¡æ¿æ–‡ä»¶**ï¼š`vat/llm/prompts/translate/reflect.md`

```md
You are a professional subtitle translator specializing in ${target_language}. Your goal is to produce translations that sound natural and native, not machine-translated.

<context>
Machine translation often produces technically correct but unnatural textâ€”it translates words rather than meaning, ignores context, and misses cultural nuances. Your task is to bridge this gap through reflective translation: identify machine-translation patterns in your initial attempt, then rewrite to match how native speakers actually communicate.
</context>

<terminology_and_requirements>
${custom_prompt}
</terminology_and_requirements>

<instructions>
**Stage 1: Initial Translation**
Translate the content, maintaining all information and subtitle numbering.

**Stage 2: Machine Translation Detection & Deep Analysis**
Critically examine your translation and identify:

1. **Structural rigidity**: Does it mirror source language word order unnaturally?
2. **Literal word choices**: Are there more natural/colloquial alternatives?
3. **Missing context**: What implicit meaning or tone needs to be made explicit (or vice versa)?
4. **Cultural mismatch**: Can we use local idiomsï¼ˆä¸­æ–‡æˆè¯­ï¼‰, references, or expressions to localize the translation?
5. **Register issues**: Is the formality level appropriate for the context?
6. **Native speaker test**: Would a native speaker say it this way? If not, how WOULD they say it?

For each issue found, propose specific alternatives with reasoning.

**Stage 3: Native-Quality Rewrite**
Based on your analysis, rewrite the translation to sound completely natural in ${target_language}. Ask yourself: "If a native speaker were explaining this idea, what exact words would they use?"
</instructions>

<output_format>
{
"1": {
"initial_translation": "<<< First translation >>>",
"reflection": "<<< Identify machine-translation patterns: What sounds unnatural? Why? What would a native speaker say instead? Consider structure, word choice, context, culture, register. Be specific about problems and alternatives. >>>",
"native_translation": "<<< Natural, native-quality translation that eliminates all machine-translation artifacts >>>"
},
...
}
</output_format>

<examples>
<example>
<scenario>Technical video about software development</scenario>
<input>
{
  "1": "ä»Šå¤©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è¿™ä¸ªbugæ˜¯æ€ä¹ˆäº§ç”Ÿçš„",
  "2": "ä¸»è¦æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ—¶å€™æ²¡æœ‰åšéªŒè¯"
}
</input>
<output>
{
  "1": {
    "initial_translation": "Today we will look at how this bug was generated.",
    "reflection": "Problems identified: 1) 'Today we will look at' is overly formal and stiffâ€”machine translation of 'ä»Šå¤©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹'. Native speakers would use more casual transitions. 2) 'was generated' is passive and unnatural for bugsâ€”they don't 'generate', they 'happen' or 'occur'. 3) Missing the casual, conversational tone of the original. Native alternative: 'Let's see what caused this bug' or 'So, what's behind this bug?' - much more natural for video narration.",
    "native_translation": "Let's see what's causing this bug."
  },
  "2": {
    "initial_translation": "The main reason is that we did not do validation when processing user input.",
    "reflection": "Problems: 1) 'The main reason is that' is bureaucraticâ€”direct translation of 'ä¸»è¦æ˜¯å› ä¸º'. Native speakers rarely start explanations this formally in video context. 2) 'did not do validation' is awkwardâ€”'do validation' is not idiomatic. 3) 'when processing' is correct but mechanical. Native alternatives: 'It's mainly because...' or 'Basically, we...' for the opening. 'We didn't validate' or 'We're not validating' for the action. Better: 'We're not validating user input' - concise, natural, appropriate register.",
    "native_translation": "Basically, we're not validating user input."
  }
}
</output>
</example>

<example>
<scenario>Casual vlog with young audience</scenario>
<input>
{
  "1": "è¿™ä¸ªåœ°æ–¹çœŸçš„å¤ªç¾äº†æˆ‘éƒ½ä¸æƒ³èµ°äº†",
  "2": "ä½ ä»¬ä¸€å®šè¦æ¥æ‰“å¡å•Š"
}
</input>
<output>
{
  "1": {
    "initial_translation": "This place is really too beautiful, I don't want to leave.",
    "reflection": "Problems: 1) 'å¤ª...äº†' translated as 'too...+adjective' misses the Chinese emphatic patternâ€”it doesn't mean 'excessively' but 'extremely/so'. 2) Structure is choppy and unnaturalâ€”comma splice feels translated. 3) Missing the enthusiastic, spontaneous tone. 4) 'I don't want to leave' is flat compared to the original's emotion. Native speaker would use: 'This place is SO gorgeous' or 'absolutely stunning' for emphasis. For the second part: 'I could stay here forever' or 'I never want to leave' captures the emotion better. Combine naturally: 'This place is absolutely stunningâ€”I never want to leave!'",
    "native_translation": "This place is absolutely stunningâ€”I could stay here forever!"
  },
  "2": {
    "initial_translation": "You all must come to check in.",
    "reflection": "Major problems: 1) 'æ‰“å¡' (daka/check-in) is a Chinese internet culture term meaning 'visit a trendy place'. Translating to 'check in' sounds like hotel check-in, completely wrong meaning. 2) 'You all must come' is stiff and imperative. 3) Missing the friendly, inviting tone. Native alternatives for 'æ‰“å¡': 'visit', 'check out this spot', 'come see this place'. For tone: 'You've gotta...' or 'You should definitely...' is more natural than 'must'. Best option: 'You've gotta check this place out!' or 'You need to visit!'â€”captures enthusiasm and invitation.",
    "native_translation": "You've gotta check this place out!"
  }
}
</output>
</example>
</examples>

<key_principles>
**Eliminate machine translation:**

- Avoid word-for-word translation and source language structure
- Don't translate idioms literally

**Sound native:**

- Use natural expressions for the context and audience
- Match appropriate formality level
- For Chinese: Use æˆè¯­/ä¿—è¯­/ç½‘ç»œç”¨è¯­ when naturally fitting

Goal: Natural speech, not machine translation text.
</key_principles>

```

åœ¨ä»£ç ä¸­çš„è°ƒç”¨æ–¹å¼ï¼š

```python
asr_data = subtitle_data
# å°†ASRDataè½¬æ¢ä¸ºSubtitleProcessDataåˆ—è¡¨
translate_data_list = [
    SubtitleProcessData(index=i, original_text=seg.text)
    for i, seg in enumerate(asr_data.segments, 1)
]
# åˆ†æ‰¹å¤„ç†å­—å¹•
chunks = self._split_chunks(translate_data_list)
# å¤šçº¿ç¨‹ç¿»è¯‘
translated_list = self._parallel_translate(chunks)
# è®¾ç½®å­—å¹•æ®µçš„ç¿»è¯‘æ–‡æœ¬
new_segments = self._set_segments_translated_text(
    asr_data.segments, translated_list
)
result = ASRData(new_segments)
            
# ä¿å­˜ç¿»è¯‘ç»“æœ
translated_srt = self.output_dir / "translated.srt"
result.save(str(translated_srt))
logger.info(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜: {translated_srt}")
            
return result

â€¦â€¦â€¦â€¦

def _split_chunks(
    self, translate_data_list: List[SubtitleProcessData]
) -> List[List[SubtitleProcessData]]:
    """å°†å­—å¹•åˆ†å‰²æˆå—"""
    return [
        translate_data_list[i : i + self.batch_num]
        for i in range(0, len(translate_data_list), self.batch_num)
    ]
def _parallel_translate(
    self, chunks: List[List[SubtitleProcessData]]
) -> List[SubtitleProcessData]:
    """å¹¶è¡Œç¿»è¯‘æ‰€æœ‰å—"""
    futures = []
    translated_list = []
    failed_chunks = []
    for chunk in chunks:
        future = self.executor.submit(self._safe_translate_chunk, chunk)
        futures.append((future, chunk))
    for future, chunk in futures:
        if not self.is_running:
            break
        try:
            result = future.result()
            translated_list.extend(result)
        except Exception as e:
            logger.error(f"ç¿»è¯‘å—å¤±è´¥ï¼š{str(e)}")
            failed_chunks.append((chunk, str(e)))
            # å¤±è´¥æ—¶ä¿ç•™åŸæ–‡ï¼Œä½†æ ‡è®°ä¸ºæœªç¿»è¯‘
            for data in chunk:
                data.translated_text = data.original_text  # æ ‡è®°ä¸ºæœªç¿»è¯‘
            translated_list.extend(chunk)
    # å¦‚æœæ‰€æœ‰å—éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºå¼‚å¸¸
    if failed_chunks and len(failed_chunks) == len(chunks):
        error_messages = [f"å— {i+1}: {err}" for i, (_, err) in enumerate(failed_chunks)]
        raise RuntimeError(f"æ‰€æœ‰ç¿»è¯‘å—éƒ½å¤±è´¥äº†:\n" + "\n".join(error_messages))
    
    # å¦‚æœéƒ¨åˆ†å—å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
    if failed_chunks:
        logger.warning(f"{len(failed_chunks)}/{len(chunks)} ä¸ªç¿»è¯‘å—å¤±è´¥ï¼Œå·²ä¿ç•™åŸæ–‡")
    return translated_list

```

```python 
def _translate_chunk(
    self, subtitle_chunk: List[SubtitleProcessData]
) -> List[SubtitleProcessData]:
    """ç¿»è¯‘å­—å¹•å—"""
    logger.debug(
        f"æ­£åœ¨ç¿»è¯‘å­—å¹•ï¼š{subtitle_chunk[0].index} - {subtitle_chunk[-1].index}"
    )
    subtitle_dict = {str(data.index): data.original_text for data in subtitle_chunk}
    # è·å–æç¤ºè¯
    if self.is_reflect:
        prompt = get_prompt(
            "translate/reflect",
            target_language=self.target_language,
            custom_prompt=self.custom_prompt,
        )
    else:
        prompt = get_prompt(
            "translate/standard",
            target_language=self.target_language,
            custom_prompt=self.custom_prompt,
        )
    try:
        # æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„è¾“å…¥ï¼ˆæ–°å¢ï¼‰
        user_input = self._build_input_with_context(subtitle_dict)
        
        result_dict = self._agent_loop(prompt, user_input, expected_keys=set(subtitle_dict.keys()))
        # å¤„ç†åæ€ç¿»è¯‘æ¨¡å¼çš„ç»“æœ
        if self.is_reflect and isinstance(result_dict, dict):
            processed_result = {
                k: f"{v.get('native_translation', v) if isinstance(v, dict) else v}"
                for k, v in result_dict.items()
            }
        else:
            processed_result = {k: f"{v}" for k, v in result_dict.items()}
        # ä¿å­˜å½“å‰ batch ç»“æœä¾›ä¸‹æ¬¡ä½¿ç”¨ï¼ˆæ–°å¢ï¼‰
        self._previous_batch_result = processed_result.copy()
        for data in subtitle_chunk:
            data.translated_text = processed_result.get(
                str(data.index), data.original_text
            )
        return subtitle_chunk
    except openai.RateLimitError as e:
        logger.error(f"OpenAI Rate Limit Error: {str(e)}")
        # Rate limit é”™è¯¯å¯ä»¥é‡è¯•ï¼Œä½†è¿™é‡Œåº”è¯¥æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
        raise
    except openai.AuthenticationError as e:
        logger.error(f"OpenAI Authentication Error: {str(e)}")
        # è®¤è¯é”™è¯¯åº”è¯¥ç«‹å³å¤±è´¥ï¼Œä¸åº”è¯¥é™çº§å¤„ç†
        raise RuntimeError(f"API è®¤è¯å¤±è´¥: {str(e)}") from e
    except openai.NotFoundError as e:
        logger.error(f"OpenAI NotFound Error: {str(e)}")
        # æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯åº”è¯¥ç«‹å³å¤±è´¥
        raise RuntimeError(f"æ¨¡å‹ä¸å­˜åœ¨: {str(e)}") from e
    except Exception as e:
        import traceback
        logger.error(f"ç¿»è¯‘å—å¤±è´¥: {str(e)}, å°è¯•é™çº§å¤„ç†,traceback: {traceback.format_exc()}")
        # å…¶ä»–é”™è¯¯å°è¯•é™çº§å¤„ç†
        try:
            return self._translate_chunk_single(subtitle_chunk)
        except Exception as fallback_error:
            logger.error(f"é™çº§ç¿»è¯‘ä¹Ÿå¤±è´¥: {str(fallback_error)}")
            # å¦‚æœé™çº§ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            raise RuntimeError(f"ç¿»è¯‘å¤±è´¥ä¸”é™çº§å¤„ç†ä¹Ÿå¤±è´¥: {str(e)}") from e
def _agent_loop(
    self, 
    system_prompt: str, 
    user_input: str,
    expected_keys: Optional[set] = None
) -> Dict[str, str]:
    """Agent loopç¿»è¯‘/ä¼˜åŒ–å­—å¹•å—"""
    assert system_prompt, "è°ƒç”¨å¥‘çº¦é”™è¯¯: system_prompt ä¸èƒ½ä¸ºç©º"
    assert user_input, "è°ƒç”¨å¥‘çº¦é”™è¯¯: user_input ä¸èƒ½ä¸ºç©º"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input},
    ]
    last_response_dict = None
    
    for _ in range(self.MAX_STEPS):
        response = call_llm(messages=messages, model=self.model)
        if not response or not response.choices:
            raise RuntimeError("LLM æœªè¿”å›æœ‰æ•ˆå“åº”")
        
        content = response.choices[0].message.content.strip()
        if not content:
            raise RuntimeError("LLM è¿”å›å†…å®¹ä¸ºç©º")
        
        response_dict = json_repair.loads(content)
        last_response_dict = response_dict
        
        # ä½¿ç”¨ expected_keys éªŒè¯ï¼ˆå¦‚æœæä¾›ï¼‰
        validation_keys = expected_keys if expected_keys else set(response_dict.keys())
        is_valid, error_message = self._validate_llm_response(
            response_dict, validation_keys
        )
        if is_valid:
            return response_dict
        else:
            messages.append({
                "role": "assistant",
                "content": json.dumps(response_dict, ensure_ascii=False),
            })
            messages.append({
                "role": "user",
                "content": f"Error: {error_message}\n\n"
                          f"Fix the errors above and output ONLY a valid JSON dictionary with ALL {len(validation_keys)} keys",
            })
    return last_response_dict
def _validate_llm_response(
    self, response_dict: Any, expected_keys: set
) -> Tuple[bool, str]:
    """éªŒè¯LLMç¿»è¯‘ç»“æœï¼ˆæ”¯æŒæ™®é€šå’Œåæ€æ¨¡å¼ï¼‰"""
    if not isinstance(response_dict, dict):
        return (
            False,
            f"Output must be a dict, got {type(response_dict).__name__}. Use format: {{'0': 'text', '1': 'text'}}",
        )
    actual_keys = set(response_dict.keys())
    def sort_keys(keys):
        return sorted(keys, key=lambda x: int(x) if x.isdigit() else x)
    if expected_keys != actual_keys:
        missing = expected_keys - actual_keys
        extra = actual_keys - expected_keys
        error_parts = []
        if missing:
            error_parts.append(
                f"Missing keys {sort_keys(missing)} - you must translate these items"
            )
        if extra:
            error_parts.append(
                f"Extra keys {sort_keys(extra)} - these keys are not in input, remove them"
            )
        return (False, "; ".join(error_parts))
    # å¦‚æœæ˜¯åæ€æ¨¡å¼ï¼Œæ£€æŸ¥åµŒå¥—ç»“æ„
    if self.is_reflect:
        for key, value in response_dict.items():
            if not isinstance(value, dict):
                return (
                    False,
                    f"Key '{key}': value must be a dict with 'native_translation' field. Got {type(value).__name__}.",
                )
            if "native_translation" not in value:
                available_keys = list(value.keys())
                return (
                    False,
                    f"Key '{key}': missing 'native_translation' field. Found keys: {available_keys}. Must include 
'native_translation'.",
                )
    return True, ""

def _build_input_with_context(self, subtitle_dict: Dict[str, str]) -> str:
        """
        æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„è¾“å…¥
        
        Args:
            subtitle_dict: å½“å‰ batch çš„å­—å¹•å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„è¾“å…¥å­—ç¬¦ä¸²
        """
        if not self.enable_context or self._previous_batch_result is None:
            # ç¬¬ä¸€ä¸ª batch æˆ–æœªå¯ç”¨ä¸Šä¸‹æ–‡
            return json.dumps(subtitle_dict, ensure_ascii=False)
        
        # æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†
        context_lines = []
        for key, text in self._previous_batch_result.items():
            context_lines.append(f"[{key}]: {text}")
        
        context_text = "\n".join(context_lines)
        
        # ç»„åˆæ ¼å¼
        input_text = f"""Previous context (for reference only, maintain consistency with these translations, but DO NOT TRANSLATE THE PREVIOUS CONTEXT ITSELF):
{context_text}

Translate the following (output ONLY these keys):
{json.dumps(subtitle_dict, ensure_ascii=False)}"""
        
        return input_text
```

é‚£ä¹ˆè¿™ä¸ªå°±æ˜¯reflectçš„ç¿»è¯‘æç¤ºè¯æ¨¡æ¿ï¼Œä»¥åŠä»–åœ¨ä»£ç ä¸­æ˜¯å¦‚ä½•è¢«ä½¿ç”¨çš„äº†ã€‚
è¯·ä½ è€ƒè™‘å¦‚ä½•ä¼˜åŒ–ï¼Œå‚è€ƒæˆ‘ä¸Šé¢è®²çš„å†…å®¹

### ä½ç½® 2ï¼šç¿»è¯‘è‡ªå®šä¹‰æç¤ºè¯ï¼ˆé…ç½®ï¼‰
**é…ç½®å­—æ®µ**ï¼š`config/default.yaml` â†’ `translator.llm.custom_prompt`

```yaml
translator:
  llm:
    model: "gpt-5-nano"                    # ç¿»è¯‘æ¨¡å‹
    enable_reflect: true                    # åæ€ç¿»è¯‘ï¼ˆå¯ç”¨åè´¨é‡æ›´é«˜ï¼Œä½†æ¶ˆè€—æ›´å¤š tokenï¼‰
    batch_size: 20                          # æ¯æ‰¹å¤„ç†çš„å­—å¹•æ•°é‡
    thread_num: 5                           # å¹¶å‘çº¿ç¨‹æ•°
    custom_prompt: "fubuki"                       # è‡ªå®šä¹‰æç¤ºè¯æ–‡ä»¶åï¼ˆç›¸å¯¹äº vat/llm/prompts/custom/ï¼‰ï¼Œå¦‚ "translate/example.md"ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸ä½¿ç”¨
    enable_context: true                    # æ˜¯å¦å¯ç”¨å‰æ–‡ä¸Šä¸‹æ–‡ï¼ˆæ–°å¢ï¼‰
```

æ­¤å¤„çš„customæç¤ºè¯çš„è¦æ±‚å³ä¸Šè¿°æ‰€è¯´ï¼Œä¸»è¦æ˜¯é’ˆå¯¹ç™½ä¸Šå¹é›ªè¿™ä¸ªæƒ…æ™¯ç‰¹åŒ–ã€‚



### ä½ç½® 3ï¼šç¿»è¯‘åœºæ™¯ç‰¹å®šæç¤ºè¯ï¼ˆæ–°å¢ï¼‰
**é…ç½®æ–‡ä»¶**ï¼š`vat/llm/scenes.yaml` â†’ `scenes[i].prompts.translate`

æ¯ä¸ªåœºæ™¯çš„ç¿»è¯‘æç¤ºè¯ä¼šåœ¨ç¿»è¯‘æ—¶åŠ è½½å¹¶ä¸å…¨å±€ `custom_prompt` åˆå¹¶ã€‚åœºæ™¯æç¤ºè¯ä¼˜å…ˆçº§æ›´é«˜ï¼Œä¼šå…ˆè¢«æ·»åŠ åˆ°æç¤ºè¯å¼€å¤´ã€‚

#### ç¤ºä¾‹ï¼šæ¸¸æˆç›´æ’­çš„ç¿»è¯‘è§„åˆ™
```yaml
scenes:
  - id: "gaming"
    name: "æ¸¸æˆç›´æ’­"
    prompts:
      translate: |
        ## æ¸¸æˆç›´æ’­ç¿»è¯‘è¦ç‚¹
        - Boss/Skill/HP ç­‰æœ¯è¯­ä¿æŒè‹±æ–‡ä¸ç¿»è¯‘ï¼Œæˆ–ç”¨æ¸¸æˆç¤¾åŒºé€šç”¨æœ¯è¯­
        - "è‰"å¯è¯‘ä¸º"ç¬‘æ­»"ã€"hhh"æˆ–"å“ˆå“ˆ"ï¼Œè§†è¯­å¢ƒ
        - "å¯„äº†"æ˜¯æ¸¸æˆç¤¾åŒºç”¨è¯­ï¼Œè¡¨ç¤ºå®Œè›‹äº†ï¼Œè¯‘ä¸º"It's over"/"We're done"æˆ–ä¿æŒåŸæ–‡
        - æˆ˜æ–—åœºæ™¯ç”¨è¯ç®€çŸ­æœ‰åŠ›ï¼š"å†²"ã€"æ’¤"ã€"èº²"ã€"ä¸Š"
        - å¤±è´¥/æˆåŠŸæ—¶çš„æƒ…ç»ªå¼ºçƒˆï¼Œä¸è¦ç¿»è¯‘å¾—å¹³æ·¡
```

### ä½ç½® 4ï¼šç¿»è¯‘ä¸Šä¸‹æ–‡ï¼ˆæ–°å¢ï¼‰
**é…ç½®å­—æ®µ**ï¼š`config/default.yaml` â†’ `translator.llm.enable_context`

å½“å¯ç”¨æ—¶ï¼Œç¿»è¯‘æ¯ä¸ªå­—å¹•æ‰¹æ¬¡ï¼ˆbatchï¼‰æ—¶ï¼ŒLLM ä¼šçœ‹åˆ°å‰ä¸€ä¸ª batch çš„ç¿»è¯‘ç»“æœä½œä¸ºå‚è€ƒä¸Šä¸‹æ–‡ï¼š

```
Previous context (for reference only, maintain consistency with these translations, but DO NOT TRANSLATE THE PREVIOUS CONTEXT ITSELF):
[å‰ä¸€ batch çš„ç¿»è¯‘ç»“æœ]

[å½“å‰ batch çš„å­—å¹•]
```

è¿™æ ·å¯ä»¥ç¡®ä¿ï¼š
- æœ¯è¯­ä¸€è‡´æ€§ï¼ˆåŒä¸€ä¸ªæ¸¸æˆæœ¯è¯­å§‹ç»ˆç”¨åŒä¸€ä¸ªç¿»è¯‘ï¼‰
- äººç‰©ç§°å‘¼ä¸€è‡´ï¼ˆä¸»æ’­ã€è§‚ä¼—æ˜µç§°ç»Ÿä¸€ï¼‰
- è¯­æ°”è¿è´¯æ€§ï¼ˆä¸ä¼šå‡ºç°å‰åè¯­æ°”å·®å¼‚å¤ªå¤§ï¼‰

**é»˜è®¤å¯ç”¨** (`enable_context: true`)ï¼Œå¯é€šè¿‡é…ç½®å…³é—­ã€‚

---

## ğŸ“ ä¼˜åŒ–æµç¨‹æ€»ç»“

### é›¶ä»£ç ä¼˜åŒ–æµç¨‹ï¼ˆæ¨èï¼‰

1. **ç¬¬ä¸€æ­¥ï¼šWhisper initial_prompt**
   - æ ¹æ®è§†é¢‘ç±»å‹ï¼ˆæ¸¸æˆ/é—²èŠ/ASMRï¼‰å¡«å†™åœºæ™¯æè¿°å’Œå…³é”®æœ¯è¯­
   - ç”¨è‹±æ–‡ï¼Œ50-200 å­—ç¬¦

2. **ç¬¬äºŒæ­¥ï¼šè°ƒæ•´æ–­å¥é•¿åº¦**
   - æ¸¸æˆç›´æ’­ï¼š16-20 å­—
   - é—²èŠç›´æ’­ï¼š24-28 å­—
   - ASMRï¼š12-18 å­—

3. **ç¬¬ä¸‰æ­¥ï¼šé…ç½®å­—å¹•ä¼˜åŒ–**ï¼ˆå¯é€‰ï¼‰
   - å¼€å¯ `translator.llm.optimize.enable: true`
   - å¡«å†™ `optimize.custom_prompt`ï¼šæœ¯è¯­è¡¨ã€ä¸»æ’­å£ç™–ã€å¸¸è§é”™è¯¯

4. **ç¬¬å››æ­¥ï¼šé…ç½®ç¿»è¯‘æç¤ºè¯**ï¼ˆå¯é€‰ï¼‰
   - å¡«å†™ `translator.llm.custom_prompt`ï¼šæ¸¸æˆæœ¯è¯­ã€ç¿»è¯‘é£æ ¼ã€ä¸»æ’­ç‰¹ç‚¹
   - å¼€å¯ `enable_reflect: true` æé«˜è´¨é‡
   - ä¿æŒ `enable_context: true` ä»¥è·å¾—æœ¯è¯­ä¸€è‡´æ€§

5. **ç¬¬äº”æ­¥ï¼šè°ƒæ•´æ–­å¥åˆ†å—å‚æ•°**ï¼ˆé’ˆå¯¹é•¿è§†é¢‘ï¼‰
   - `chunk_size_sentences`: é»˜è®¤ 50ï¼Œå¯è°ƒè‡³ 30-100
   - `chunk_overlap_sentences`: é»˜è®¤ 5ï¼Œå¯è°ƒè‡³ 3-10
   - `chunk_min_threshold`: é»˜è®¤ 30ï¼ŒçŸ­è§†é¢‘å¯æé«˜è‡³ 50+

6. **ç¬¬å…­æ­¥ï¼šæŸ¥çœ‹åœºæ™¯é…ç½®**ï¼ˆè‡ªåŠ¨åº”ç”¨ï¼‰
   - æŸ¥çœ‹ `vat/llm/scenes.yaml` ä¸­çš„ 5 ä¸ªåœºæ™¯é¢„è®¾
   - è§†é¢‘ä¼šè‡ªåŠ¨è¯†åˆ«åœºæ™¯å¹¶åŠ è½½å¯¹åº”çš„ split/translate/optimize æç¤ºè¯

### ä»£ç çº§ä¼˜åŒ–ï¼ˆè‹¥éœ€è¿›é˜¶ï¼‰

7. **ä¿®æ”¹æ–­å¥æç¤ºè¯æ¨¡æ¿**
   - ç¼–è¾‘ `vat/llm/prompts/split/sentence.md`
   - å¢åŠ  vtuber ç›´æ’­è§„åˆ™ï¼ˆå£ç™–ã€æ¸¸æˆæœ¯è¯­ã€é‡å¤æ„Ÿå¹ï¼‰

8. **ä¿®æ”¹ç¿»è¯‘æç¤ºè¯æ¨¡æ¿**
   - ç¼–è¾‘ `vat/llm/prompts/translate/standard.md` æˆ– `reflect.md`
   - å¢åŠ  vtuber ç›´æ’­ç¤ºä¾‹å’Œæ£€æŸ¥é¡¹

9. **å®šåˆ¶åœºæ™¯é…ç½®**
   - ç¼–è¾‘ `vat/llm/scenes.yaml`ï¼Œè°ƒæ•´æˆ–æ–°å¢åœºæ™¯çš„ split/translate/optimize æç¤ºè¯

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡æ¿æ–‡ä»¶ä¿®æ”¹åç«‹å³ç”Ÿæ•ˆ**ï¼ˆå› ä¸ºæœ‰ LRU ç¼“å­˜ï¼Œä½†æ¯æ¬¡è¿è¡Œä¼šé‡æ–°è¯»å–ï¼‰
2. **é…ç½®æ–‡ä»¶ä¿®æ”¹åéœ€é‡å¯è¿›ç¨‹**
3. **æç¤ºè¯é•¿åº¦æ§åˆ¶**ï¼š
   - `custom_prompt` å»ºè®® 500-2000 å­—ç¬¦
   - è¿‡é•¿ä¼šå¢åŠ  token æˆæœ¬ä¸”å¯èƒ½é™ä½å“åº”è´¨é‡
4. **æµ‹è¯•éªŒè¯**ï¼š
   - ä¿®æ”¹åå…ˆç”¨çŸ­è§†é¢‘ï¼ˆ5-10åˆ†é’Ÿï¼‰æµ‹è¯•æ•ˆæœ
   - å¯¹æ¯” `original_raw.srt` vs `original_split.srt`ï¼ˆæ–­å¥æ•ˆæœï¼‰
   - å¯¹æ¯” `original.srt` vs `translated.srt`ï¼ˆç¿»è¯‘è´¨é‡ï¼‰

---

**æœ¬æ–‡æ¡£æ¶µç›–äº†æ‰€æœ‰é›¶ä»£ç ä¿®æ”¹çš„æç¤ºè¯ä¼˜åŒ–ä½ç½®ã€‚æ‰€æœ‰åŠŸèƒ½å·²é€šè¿‡ä»£ç å®ç°ï¼ŒåŒ…æ‹¬åœºæ™¯è‡ªåŠ¨è¯†åˆ«ã€åˆ†å—æ–­å¥å¤„ç†ã€ç¿»è¯‘ä¸Šä¸‹æ–‡ä¼ é€’ç­‰ã€‚**
